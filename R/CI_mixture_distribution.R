WORK_WITH_THREADS = F # A constant setting if computation of the CIs for the mixing distribution should be done in a multithreaded computation. Currently, this is disabled, since the open/close times of many threads are slower than simply holding multiple R processes open and sendig commands to them.

# Classes related to CI estimation of the mixing distribution:
CLASS.NAME.MCLEOD.CI = 'mcleod.CI.obj' # this is the resulting object, when estimating the mixing distribution
CLASS.NAME.MCLEOD.CI.RHO = 'mcleod.CI.obj.rho' # a calibration object, telling what value of rho (shift parameter) will be used for each value of theta (when testing GE/LE hypotheses)
CLASS.NAME.MCLEOD.CI.PARAMETERS = 'mcleod.CI.obj.parameters' # a container object for parameters
CLASS.NAME.MCLEOD.CI.DECONV.BANK = 'mcleod.CI.obj.deconv.bank' # this object contains a cache for a lazy evaluation layer, holding estimated CDFs of the mixing distributions from Worst Case data genetaions (LE/GE type worst case hypotheses)


#' An internal function used to verify logic of q_vec and theta_vec
#'
#' An internal function used to verify that: 1) q_vec contains the same values as 1-q_vec (for binomial sampling distribution);
#'  2) that all values in q_vec_for_computation and 1-q_vec_for_computation are found in q_vec;
#'   3) q_vec values are between 0 and 1; 4) theta_vec contains all values found in theta_vec_for_computation; 5) for binomial sampling - theta_vec contains all values also found in -1*theta_vec.
#' @param q_vec same parameter as in mcleod.CI.estimation.parameters
#' @param q_vec_for_computation same parameter as in mcleod.CI.estimation.parameters
#' @param theta_vec same parameter as in mcleod.CI.estimation.parameters
#' @param theta_vec_for_computation same parameter as in mcleod.CI.estimation.parameters
#' @param sampling_distribution same parameter as in mcleod.CI.estimation.parameters
#'
#' @return returns a list with q_vec,q_vec_for_computation,theta_vec,theta_vec_for_computation, n_q and n_theta, to be updated in CI_params object
#' @export
#' @keywords internal
#' @examples see internal code usages
verify_q_and_theta_vec = function(q_vec,q_vec_for_computation,theta_vec,theta_vec_for_computation,sampling_distribution){
  rounding_nr_digits = 6
  #check that q_vec and theta_vec include q_vec_for_computation and theta_vec_for_computation, respectively. We enforce that , by adding required values.
  q_vec = sort(unique(round(c(q_vec,q_vec_for_computation),digits = rounding_nr_digits)))
  theta_vec = sort(unique(round(c(theta_vec,theta_vec_for_computation),digits = rounding_nr_digits)))
  
  #for binomial sampling, q must contain same values as 1-q, and theta must have same values as -theta. We enforce that as well, by adding required values.
  if(sampling_distribution == 'binomial'){
    q_vec = sort(unique(round(c(q_vec, 1 - q_vec),digits = rounding_nr_digits)))
    theta_vec = sort(unique(round(c(theta_vec,-theta_vec),digits = rounding_nr_digits)))
  }else if (sampling_distribution == 'poisson'){
    #nothing to do for now...
  }
  
  if(any(q_vec<0) | any(q_vec>1)){
    stop('q_vec and q_vec_for_computation must be between 0 and 1')
  }
  
  
  return(list(q_vec = q_vec,
              q_vec_for_computation = q_vec_for_computation,
              theta_vec = theta_vec,
              theta_vec_for_computation = theta_vec_for_computation,
              n_q = length(q_vec),
              n_theta = length(theta_vec)))
}



#' Constructs container for parameters used when building CIs for the mixing distribution
#' 
#' Constructs an object containing the parameters used in \code{\link{mcleod.estimate.CI}} for estimating point-wise confidence intervals for quantiles and percentiles of the mixing distribution, for binomial/poisson generated samples.
#' 
#' @details See package vignette for a thorough explanantion on how the mixing distribution is estimated. Also, see package vignette on the meaning of the parameter rho, the procedure for estimating rho, and its parameters.
#'
#' @param q_vec When estimating CIs/ CI curves of the mixing distribution, this vector sets the possible percentiles over which CIs are built (values in the range (0,1)).
#' @param theta_vec When estimating CIs/ CI curves of the mixing distribution, this vector sets the possible quantiles over which CIs are built (values are deviates of the random effect distribution, defined using the same units as \code{a.limits}).
#' @param a.limits a vector of size 2, setting the minimum and maximum values of the support of the mixing distribution. For binomial sampling distributions - this sets the support of the log odds of p (the probability for a successfull draw). For poisson errors, this sets the support of log(lambda), with lambda being the Poisson rate.
#' @param sampling_distribution either 'binomial' or 'poisson' (lower case), sets the sampling distribution
#' @param comp_parameters object generated by mcleod.computational.parameters(), sets computational parameters for the deconvolution algorithm estimating the mixing distribution.
#' @param prior_parameters object generated by mcleod.prior.parameters(), sets computational parameters for the deconvolution algorithm estimating the mixing distribution.
#' @param nr.perms when performing one sided tests for GE/LE hypotheses, this is the number of permutations performed.
#' @param alpha.CI the confidence level of two-sided pointwise confidence intervals (by quantile percentile). The confidence intervals are constructed by inverting one sided tests at significance level (1-alpha.CI)/2
#' @param rho.calibration.method one of 'max', 'sum', 'specific': sets how rho is selected via calibration. 'max' chooses the rho with the minimum maximum distance between LE and GE curves for the holdout data; 'sum' chooses 'rho' with the minimum sum of distances between GE and LE curves; 'specific' chooses different rhos for different values of theta (the natural parameter)
#' @param rho.set.value default is NA, meaning this value of rho (shift parameter when testing LE/GE hypothesis) is set adaptively from the data. If this is set to a positive value, this value of rho will be used when testing LE/GE hypotheses. Setting this parameter to a value different than NA will disable the calibration selected by the parameter rho.calibration.method
#' @param rho.possible.values The possible values of rho considered as candidates when trying to estimate best value of rho for the data
#' @param rho.estimation.perm When estimating rho adaptively- sets the number of permutations used to construct the pointwise confidence intervals for the holdout data
#' @param rho.q_for_calibration When estimating rho adaptively- CIs for the CDF values will be built at the quantiles matching these values in the holdout data.  
#' @param rho.theta_for_calibration When estimating rho adaptively- if this parameter is set to a value other than null, the adaptive estimation of rho will be performed using CIs built for this value of theta (random effect value)
#' @param rho.calibration.nr.points.for.pv.exterpolation When estimating rho adaptively- for how many point should a P-value be computed, in order to interpolate the PV (at a given theta) across q, and find the edges of the CI (for the given theta)
#' @param q_vec_for_computation When running mcleod.estimate.CI() with compute_P_values_over_grid set to true - this will evaluate one sided P-values only for the percentiles defined by q_vec_for_computation, and not for all values defined by q_vec. This is used internally by mcleod.estimate.CI.single.q(), when constructing CIs for the mixing distributions across values of theta (quantile), for a single value of (percentile).
#' @param theta_vec_for_computation When running mcleod.estimate.CI() with compute_P_values_over_grid set to true - this will evaluate one sided P-values only for the quantiles defined by theta_vec_for_computation, and not for all values defined by theta_vec. This is used internally by mcleod.estimate.CI.single.theta(), when constructing CIs for the mixing distributions across values of q (percentile), for a single value of theta (quantile).
#' @param P_values_grid_compute_univariate_CI An interval parameter, set to T by the functions mcleod.estimate.CI.single.q and mcleod.estimate.CI.single.theta in order to indicate that only a single CI is computed - either by theta or by q.
#' @param do_serial When set to T, all computations will be done on a single core 
#' @param nr.cores When computations are done on multiple cores - set the number of cores. The default value is ceiling(detectCores()/2)
#'
#' @return
#' @export
#'
#' @examples
mcleod.CI.estimation.parameters = function(q_vec = seq(0.05,0.95,0.05),
                                           theta_vec = seq(-3,3,0.25),
                                           a.limits = c(-5,5),
                                           sampling_distribution = 'binomial',
                                           comp_parameters = mcleod.computational.parameters(),
                                           prior_parameters = mcleod.prior.parameters(),
                                           nr.perms = 200,
                                           alpha.CI = 0.95,
                                           rho.calibration.method = 'sum', #'max', 'sum', 'specific'
                                           rho.set.value = NA,
                                           rho.possible.values = seq(0.1,0.5,0.1),
                                           rho.estimation.perm = 200,
                                           rho.q_for_calibration = seq(0.1,0.9,0.1),
                                           rho.theta_for_calibration = NULL,
                                           rho.alpha.CI = alpha.CI,
                                           rho.calibration.nr.points.for.pv.exterpolation = 5,
                                           q_vec_for_computation = NULL,
                                           theta_vec_for_computation = NULL,
                                           P_values_grid_compute_univariate_CI = F,
                                           do_serial = F,
                                           nr.cores = ceiling(detectCores()/2)){
  
  if(!(sampling_distribution %in% c('binomial','poisson'))){
    stop('parameter sampling_distribution must be either \'binomial\' or \'poisson\'')
  }
  
  #the default is to compute CIs for all q_vec
  if(is.null(q_vec_for_computation)){
    q_vec_for_computation = q_vec
  }
  
  #the default is to compute CIs for all theta_vec
  if(is.null(theta_vec_for_computation)){
    theta_vec_for_computation = theta_vec
  }

  #verify logic on these parameters, see function description
  verified_q_and_theta_vectors = verify_q_and_theta_vec(q_vec = q_vec,
                         q_vec_for_computation = q_vec_for_computation,
                         theta_vec = theta_vec,
                         theta_vec_for_computation = theta_vec_for_computation,
                         sampling_distribution = sampling_distribution)
  
  #reinstate validated parameters
  q_vec = verified_q_and_theta_vectors$q_vec
  q_vec_for_computation = verified_q_and_theta_vectors$q_vec_for_computation
  theta_vec = verified_q_and_theta_vectors$theta_vec
  theta_vec_for_computation = verified_q_and_theta_vectors$theta_vec_for_computation
  
  #continue running checks:
  if(length(a.limits)!=2 | is.unsorted(a.limits)){
    stop('a.limits must be an ordered numeric vector of size 2')
  }
  
  if(sampling_distribution == 'binomial'){
    if(a.limits[1] != -1* a.limits[2])
      stop('for binomial sampling distribution, a.limits must be symmetric around 0')
  }
  
  if(alpha.CI <0 | alpha.CI > 1 ){
    stop('coverage rating must be a number between 0 and 1')
  }
  if(rho.alpha.CI <0 | rho.alpha.CI > 1 ){
    stop('rho.alpha.CI - coverage rating must be a number between 0 and 1')
  }
  
  
  if(alpha.CI<0.5){
    warning('alpha.CI sets the coverage probability, typical values are 0.95, 0.9')
  }
  if(nr.perms != as.integer(nr.perms))
    stop('nr.perms must be integer, larger than 0 (typical values are 200 and above)')
  if(nr.perms<0){
    stop('nr.perms must be positive')
  }
  if(nr.perms<100){
    warning('nr.perms smaller than 100 - typical values are 200 and above...')
  }
  
  if(!is.logical(do_serial))
    stop('do_serial must be a logical variable')
  
  if(!is.logical(P_values_grid_compute_univariate_CI))
    stop('P_values_grid_compute_univariate_CI must be a logical variable')
  
  if(!is.na(rho.set.value)){
    if(rho.set.value<0)
      stop('when setting rho manually using rho.set.value, it must be larger than 0. Typical values are 0.1-0.5 .')
  }
  
  if(any(rho.possible.values<0)){
    stop('possible values in rho.possible.values must be larger than 0')
  }
  
  if(any(rho.possible.values>1)){
    warning('typical values in rho.possible.values should by 0.1-1.0, we optimal values ususally set in the range 0.1-1.0')
  }
  
  if(rho.estimation.perm != as.integer(rho.estimation.perm))
    stop('rho.estimation.perm must be integer, larger than 0 (typical values are 50-100)')
  if(rho.estimation.perm<0){
    stop('rho.estimation.perm must be positive')
  }
  if(rho.estimation.perm>100){
    warning('rho.estimation.perm larger than 100 - ussually values in the range 50-100 are sufficient.')
  }
  
  if(rho.calibration.nr.points.for.pv.exterpolation != as.integer(rho.calibration.nr.points.for.pv.exterpolation))
    stop('rho.calibration.nr.points.for.pv.exterpolation must be an integer, larger than 2. Typical values are in the range [3,5].')
  
  if(rho.calibration.nr.points.for.pv.exterpolation > 5)
    stop('rho.calibration.nr.points.for.pv.exterpolation is typically in the range [3,5], make sure this value was set correctly...')
  
  if(is.unsorted(rho.possible.values))
    stop('rho.possible.values must be sorted')
  
  if(any(rho.q_for_calibration<0) | any(rho.q_for_calibration>1))
    stop('rho.q_for_calibration must be between 0 and 1')
  
  if(is.unsorted(rho.q_for_calibration))
    stop('rho.q_for_calibration must be sorted')
  
  if(!(rho.calibration.method %in% c('max', 'sum', 'specific'))){
    stop('rho.calibration.method must be \'max\', \'sum\', or \'specific\' ')
  }
  
  #NOTE: there is no need to verify the type of comp_parameters and prior_params: since mcleod verifies this internally in the deconvolution function
  
  #pack as an object
  ret = list()
  ret$q_vec = q_vec
  ret$n_q = length(q_vec)
  ret$theta_vec = theta_vec
  ret$n_theta = length(theta_vec)
  ret$a.limits = a.limits
  ret$sampling_distribution = sampling_distribution
  ret$comp_parameters = comp_parameters
  ret$prior_parameters = prior_parameters
  ret$rho.calibration.method = rho.calibration.method
  ret$rho.set.value = rho.set.value
  ret$nr.cores = nr.cores
  ret$nr.perms = nr.perms
  ret$alpha.CI = alpha.CI
  ret$do_serial = do_serial
  ret$rho.possible.values = rho.possible.values
  ret$rho.estimation.perm = rho.estimation.perm
  ret$rho.q_for_calibration = rho.q_for_calibration
  ret$rho.theta_for_calibration = rho.theta_for_calibration
  ret$rho.alpha.CI = rho.alpha.CI
  ret$rho.calibration.nr.points.for.pv.exterpolation = rho.calibration.nr.points.for.pv.exterpolation
  ret$q_vec_for_computation = q_vec_for_computation
  ret$theta_vec_for_computation = theta_vec_for_computation
  ret$P_values_grid_compute_univariate_CI = P_values_grid_compute_univariate_CI
  class(ret) = CLASS.NAME.MCLEOD.CI.PARAMETERS
  return(ret)
}




#' Internal function used for generating a smart cache, for faster generation of Pki matrices
#'
#' @param n.vec vector of number of draws per sample
#' @param a.max used to define the support using the parameterization (-a.max,a.max)
#' @param prior_param result from \code{\link{mcleod.prior.parameters}}
#' @param comp_param result from \code{\link{mcleod.computational.parameters}}
#'
#' @return returns a list with functions and lookup tables for generating Pki matrices
#' @export
#' @keywords internal
#' @examples
#' function returns the hashtables, precomputed entries and functions to the user.
#' the user can now generate a PKI matrix more efficiently using (with gen_object being the object returned from this function):
#' sorted_n_data = gen_object$sorted_n_data
#' n_to_P_k_i_generator_index = gen_object$n_to_P_k_i_generator_index
#' generate_P_k_i_generator_list = gen_object$generate_P_k_i_generator_list
#' generator_list = gen_object$generator_list
#' generate_P_k_i = gen_object$generate_P_k_i
#' a.vec = gen_object$a.vec
#' generated_P_k_i_matrix = generate_P_k_i(X_sampled,length(a.vec)-1,N_vec)
generate_P_k_i_matrix_cache = function(n.vec,a.max,prior_param,comp_param){
  
  #these are the unique values for the number of draws
  sorted_n_data = sort(unique(n.vec))
  
  #we form a hash table, indexing the sorted unique number of draws. For each unique n -> index. Due to a technical constraint we have to use characters as keys
  n_to_P_k_i_generator_index = hash()
  for(i in 1:length(sorted_n_data))
    n_to_P_k_i_generator_index[ as.character(sorted_n_data[i]) ] = i
  
  # this is a function called once for the data, that generate for each n a matrix of size (n+1, length(a.vec)-1), giving the probabilities for X to recive a value between 0 and n (by row), given that the random effect deviate is in the segment associated with the column.
  # the different matrices are returned as a list.
  generate_P_k_i_generator_list = function(n_vec = 1:20){
    P_k_i_generator_list = hash() #list()
    for(n_i in 1:length(n_vec)){
      n = n_vec[n_i]
      n.smp = rep(n,n+1)
      x.smp = c(0:n)
      
      P_k_i_for_n = mcleod(x.smp = x.smp,n.smp = n.smp,
                           a.limits = c(-a.max,a.max),
                           computational_parameters = mcleod.computational.parameters(nr.gibbs = 2,
                                                                                      nr.gibbs.burnin = 1,
                                                                                      integration_step_size = comp_param$integration_step_size,
                                                                                      Fast.Gamma.Used = comp_param$Fast.Gamma.Used,
                                                                                      Fast.Gamma.Bank.Size = comp_param$Fast.Gamma.Bank.Size),
                           prior_parameters = prior_param)
      P_k_i_generator_list[[as.character(n_i)]] = P_k_i_for_n$additional$original_stat_res$p_k_i
    }
    return(P_k_i_generator_list)
  }
  
  #compute the generator list (using the above function). 
  generator_list = suppressWarnings(generate_P_k_i_generator_list(n_vec = sorted_n_data)) 
  
  # This function will receive x.smp, the number of segments in a.vec (i.e., length(a.vec)-1), and the number of draws
  # and will generate a P_ki matrix.
  generate_P_k_i = function(x_to_generate_for,n.dim,n.vec){
    K=length(n.vec)
    P_k_i_generated = matrix(NA,nrow = K,ncol = n.dim)
    for(k in 1:K){
      P_k_i_generated[k,] = (generator_list[[ 
        as.character(
          n_to_P_k_i_generator_index[[   as.character(n.vec[k])  ]]
        )
      ]])[ x_to_generate_for[k] + 1, ]
    }
    return(P_k_i_generated)
  }
  
  ret = list()
  ret$sorted_n_data = sorted_n_data
  ret$n_to_P_k_i_generator_index = n_to_P_k_i_generator_index
  ret$generate_P_k_i_generator_list = generate_P_k_i_generator_list
  ret$generator_list = generator_list
  ret$generate_P_k_i = generate_P_k_i
  return(ret)
}

#' Generate a cache for estimated CDFs of the mixing distributions, computed for worstcase (GE/LE) data
#'
#' The object is used to cache the estimated CDFs by value of (theta,q). The values median_curve_GE/median_curve_LE (returned inside the object) are double-nested lists by theta and then q, holding samples of the estimated CDFs (across mcleod's a.vec representation), by value of theta,q.
#' This object is then used throughout the pipeline to also hold CI_param.
#' @param N_vec The number of draws, for binomial observation. (when using Poisson samples, this sets the offset term, using offset = log(N) ) 
#' @param CI_param The CI parameters object used for the pipeline
#' @param Use_Existing_Permutations_From_Object an existing object generated using mcleod.estimate.CI. the cachec is instantiated using the CDF samples available in this object. It is up to the user to verify the the object uses the same CI parameters and N vec.
#'
#' @return the constructed objected for the cache, of type 'mcleod.CI.obj.deconv.bank'
#' @export
#' @keywords internal
mcleod.CI.deconv.bank.constructor = function(N_vec=NULL,CI_param,Use_Existing_Permutations_From_Object = NULL){
  n_theta = CI_param$n_theta #number of theta values
  n_q = CI_param$n_q #number of q values
  
  if(!is.null(Use_Existing_Permutations_From_Object)){ #check if the user supplied an existing object to copy the deconvolution results from
    median_curve_GE = Use_Existing_Permutations_From_Object$bank$median_curve_GE
    median_curve_LE = Use_Existing_Permutations_From_Object$bank$median_curve_LE
  }else{
    #This will hold a list of lists of lists of median curves. The first index (for the greater list) will index values of theta.
    #The second index will be by values of q. We hold two seperate lists for LE and GE hypotheses. for the binomial case one can be computed from the other, but generally (e.g., in the poisson case), this is not possible and will require two diffrent computations. Hence, we need curves for both LE and GE hypotheses.
    # The third entry will index repetitions
    median_curve_GE = list()  #init first index, for values of theta
    median_curve_LE = list()
    
    for(i in 1:n_theta){
      median_curve_GE[[i]] = list() #init second index, for value of each value of q
      median_curve_LE[[i]] = list()
      for(j in 1:n_q){
        median_curve_GE[[i]][[j]] = list() #init third index, for the sampling replicates.
        median_curve_LE[[i]][[j]] = list()
      }
    }  
  }
  
  #return the bank, along with its parameters.
  ret = list()
  ret$CI_param = CI_param #this will serve as a holder for all deconvolution and CI parameters, for the remainder of the computation.
  ret$median_curve_GE = median_curve_GE
  ret$median_curve_LE = median_curve_LE
  ret$N_vec = N_vec
  class(ret) = CLASS.NAME.MCLEOD.CI.DECONV.BANK
  return(ret)
}


#' Given a mcleod object, compute the posterior median for the random effect distribution
#' 
#' Medians are taken pointwise across a.vec
#' 
#' @param mcleod_for_data mcleod object
#'
#' @return vector of length = length(a.vec), with edge values of 0 and 1, giving the pointwise posterior medians across a.vec.
#' @export
#' @keywords internal
compute_medians_curve = function(mcleod_for_data,list_ind = NA){
  #extract the matrix givein for MCMC replicates, the probability for each segment of the distribution
  if(is.na(list_ind)){ #if mcleod_for_data contains only a single result, we extract the matrix and transpower (so after transpose MCMC samples are rows, and segments of the distribution are columns)
    pi_smp_for_data = (t(mcleod_for_data$additional$original_stat_res$pi_smp))
  }else{ #if mcleod_for_data contains multiple entries, than we extract the relevant entry from original_stat_res by index
    pi_smp_for_data = (t(mcleod_for_data$additional$original_stat_res[[list_ind]]$pi_smp))
  }
  #remove burnin samples
  pi_smp_for_data = pi_smp_for_data[-(1:mcleod_for_data$parameters_list$nr.gibbs.burnin),]
  #convert the probability distributions to CDFs, by cumsuming each MCMC sample.
  cumulative_pi_smp_for_data = t(apply(pi_smp_for_data,1,cumsum))
  # compute the median per a.vec point. We add an entry of zero for the leftmost point in the support
  # (so the returned result is of size length(a.vec))
  median_cumulative_pi_smp_for_data = c(0,apply(cumulative_pi_smp_for_data,2,median))
  return(median_cumulative_pi_smp_for_data)
}


#' Function returns a series of posterior median CDF curves, for bootstrap samples of a specific LE/GE hypothesis
#'
#' @param bank cache to use for sampling/update
#' @param ind_theta index of theta for the hypothesis for which curves are generated
#' @param ind_q index of q for the hypothesis for which curves are generated
#' @param nr.curves number of bootstrap samples required
#' @param is_GE is the hypothesis GE? (F is LE)
#' @param do_serial should computation be done in a serieal manner
#'
#' @return list of curves of posterior median CDFs. Each entry has a vector of length(a.vec). The list has \code{nr.curves} entries.
#' @export
#' @keywords internal
mcleod.CI.deconv.bank.get_median_curves_for_worst_case_hypothesis=function(bank,
                                                                           ind_theta,
                                                                           ind_q,
                                                                           nr.curves,
                                                                           is_GE = T,
                                                                           do_serial = T){
  # currently we only support one sampling distribution
  if(bank$CI_param$sampling_distribution != 'binomial')
    stop('bank only supports binomial')
  
  # used for fast generation of Pki matrices
  gen_object = NULL
  if("gen_object" %in% names(bank))
    gen_object = bank$gen_object
  
  #check how many permutations were already computed (and are available in the bank)
  if(is_GE)
    nr.computed = length(bank$median_curve_GE[[ind_theta]][[ind_q]])
  else
    nr.computed = length(bank$median_curve_LE[[ind_theta]][[ind_q]])
  
  #check how many more we need to compute
  nr.to.compute = nr.curves - nr.computed 
  
  if(nr.to.compute>0){ # if we need to compute
    
    if(bank$CI_param$sampling_distribution == 'binomial'){
      
      if(WORK_WITH_THREADS){ #one option we support is parallerl computation of MCMCs by threads. THe other option is by processes and by foreach/forRNG
        
        #the code works so that it only generates GE Worst case curves. Due to the binomial nature, solving one GE curve gives us another LE curve
        # Hence, if the user asked for an LE hypothesis, we solve the deconvolution problem for the corresponding GE deconvolution hypothesis.
        if(is_GE){ #find thetha and q by indices requested by user
          current_theta = bank$CI_param$theta_vec[ind_theta]
          current_q = bank$CI_param$q_vec[ind_q]  
        }else{ # we compute the corresponding GE hypothesis and revert the curves afterwords
          current_theta = bank$CI_param$theta_vec[bank$CI_param$n_theta - ind_theta + 1]
          current_q = bank$CI_param$q_vec[bank$CI_param$n_q - ind_q +1]  
        }
        
        #sample multiple values of the data.
        N_vec = bank$N_vec
        X_sampled_list = list()
        for(k in 1:nr.to.compute){
          P_sample = rbinom(n = length(N_vec),size = 1,1-current_q) * inv.log.odds(current_theta)
          X_sampled = rbinom(n = length(N_vec),size = N_vec,prob = P_sample)
          X_sampled_list[[k]] = X_sampled
        }
        
        #generate Pki if needed. Note that for the thread based solution, Pki is passed as a list of matrices.
        generated_P_k_i_matrix = NULL
        
        if(!is.null(gen_object)){
          sorted_n_data = gen_object$sorted_n_data
          n_to_P_k_i_generator_index = gen_object$n_to_P_k_i_generator_index
          generate_P_k_i_generator_list = gen_object$generate_P_k_i_generator_list
          generator_list = gen_object$generator_list
          generate_P_k_i = gen_object$generate_P_k_i
          a.vec = gen_object$a.vec
          generated_P_k_i_matrix = list()
          for(k in 1:nr.to.compute){
            generated_P_k_i_matrix[[k]] = generate_P_k_i(X_sampled_list[[k]],length(a.vec)-1,N_vec)  
          }
        }
        
        nr_threads = 1
        if(!do_serial)
          nr_threads = bank$CI_param$nr.cores
        
        #this is needed since the garbage collection may lag begind (due to many Cpp level objects), and cause R to crash
        gc(reset = TRUE)
        
        temp_mcleod = mcleod(x.smp = X_sampled_list,n.smp = N_vec,
                             a.limits = bank$CI_param$a.limits,
                             exact.numeric.integration = T,
                             computational_parameters = bank$CI_param$comp_parameters,
                             prior_parameters = bank$CI_param$prior_parameters,input_P_k_i = generated_P_k_i_matrix,
                             nr_threads = nr_threads)
        gc(reset = TRUE)
        
        # collect and return result
        res_Binomial = list()
        for(k in 1:nr.to.compute){
          res_Binomial[[k]] = compute_medians_curve(temp_mcleod,list_ind = k) # compute the median curve for each result. 
        }
      }else{#do parallel processes
        
        #This function solves the deconvolution problem for a single data sample, generated for a GE hypothesis.
        worker_function_Binomial_GE = function(seed){
          set.seed(seed)
          
          #get the theta and q for the GE deconvolution problem to be solved, by index requsted by the user. Again, if the user requested an LE curve, we solve for the corresponding GE deconvolution problem
          if(is_GE){
            current_theta = bank$CI_param$theta_vec[ind_theta]
            current_q = bank$CI_param$q_vec[ind_q]  
          }else{ # we compute the corresponding GE hypothesis and revert the curves afterwords
            current_theta = bank$CI_param$theta_vec[bank$CI_param$n_theta - ind_theta + 1]
            current_q = bank$CI_param$q_vec[bank$CI_param$n_q - ind_q +1]  
          }
          
          #generate worst case GE data          
          N_vec = bank$N_vec
          P_sample = rbinom(n = length(N_vec),size = 1,1-current_q) * inv.log.odds(current_theta)
          X_sampled = rbinom(n = length(N_vec),size = N_vec,prob = P_sample)
          
          library(mcleod)
          
          #compute Pki matrices efficiently, using the pregeneration mechanism.
          generated_P_k_i_matrix = NULL
          if(!is.null(gen_object)){
            sorted_n_data = gen_object$sorted_n_data
            n_to_P_k_i_generator_index = gen_object$n_to_P_k_i_generator_index
            generate_P_k_i_generator_list = gen_object$generate_P_k_i_generator_list
            generator_list = gen_object$generator_list
            generate_P_k_i = gen_object$generate_P_k_i
            a.vec = gen_object$a.vec
            generated_P_k_i_matrix = generate_P_k_i(X_sampled,length(a.vec)-1,N_vec)
          }
          
          #solve the deconvolution problem.          
          temp_mcleod = mcleod(x.smp = X_sampled,n.smp = N_vec,
                               a.limits = bank$CI_param$a.limits,
                               exact.numeric.integration = T,
                               computational_parameters = bank$CI_param$comp_parameters,
                               prior_parameters = bank$CI_param$prior_parameters,input_P_k_i = generated_P_k_i_matrix)
          
          return(compute_medians_curve(temp_mcleod))
        }
        #call for deconvolution, across the required number of times.
        if(do_serial){ #serial solution
          res_Binomial = list()
          for(k in 1:nr.to.compute){
            res_Binomial[[k]] = worker_function_Binomial_GE(k)
          }
        }else{ #parallel solution
          #this assumes a cluster is registered in the function mcleod.estimate.CI(...)
          res_Binomial = foreach(seed=(nr.computed+1):nr.curves, .options.RNG=1,
                                 .export = c('ind_theta','ind_q','bank','worker_function_Binomial_GE','gen_object')) %dorng% {
                                   worker_function_Binomial_GE(seed)
                                   
                                 }
        }
      }#end of parallel processes
      
      
      #Collecting results
      ret = list() # we generate an objected with the returned curves
      if(is_GE){
        if(nr.computed>0){ #start by filling the returned object with previously computed solutions
          for(k in 1:nr.computed){
            ret[[k]] = bank$median_curve_GE[[ind_theta]][[ind_q]][[k]]
          }
        }
        for(k in 1:length(res_Binomial)){
          #we store both the GE and the LE solutions. Note that (a) the LE solution has to be inverted. (b) we use <<- since we are working with a global object
          ret[[k + nr.computed]] = res_Binomial[[k]]
          bank$median_curve_GE[[ind_theta]][[ind_q]][[k + nr.computed]] <<- res_Binomial[[k]] 
          bank$median_curve_LE[[bank$CI_param$n_theta - ind_theta + 1]][[bank$CI_param$n_q - ind_q +1]][[k + nr.computed]] <<- rev(1- res_Binomial[[k]])
        }  
      }else{
        if(nr.computed>0){ #start by filling the returned object with previously computed solutions
          for(k in 1:nr.computed){
            ret[[k]] = bank$median_curve_LE[[ind_theta]][[ind_q]][[k]]
          }
        }
        for(k in 1:length(res_Binomial)){ #handle storing in the case we solved an LE deconvolution problem
          ret[[k + nr.computed]] = rev(1- res_Binomial[[k]])
          bank$median_curve_GE[[bank$CI_param$n_theta - ind_theta + 1]][[bank$CI_param$n_q - ind_q +1]][[k + nr.computed]] <<- res_Binomial[[k]]
          bank$median_curve_LE[[ind_theta]][[ind_q]][[k + nr.computed]] <<- rev(1- res_Binomial[[k]])
        }
      }
      
    }# end of case binomial
  }else{ # if there are none to compute, we can just take from bank
    bank_sizes = unlist(lapply(bank$median_curve_GE,function(x){unlist(lapply(x,length))}))
    #print(paste0('CACHE_HIT, bank size: ',sum(bank_sizes)))
    ret = list()
    if(is_GE){
      for(k in 1:nr.curves){
        ret[[k]] = bank$median_curve_GE[[ind_theta]][[ind_q]][[k]]
      }
    }else{
      for(k in 1:nr.curves){
        ret[[k]] = bank$median_curve_LE[[ind_theta]][[ind_q]][[k]]
      }
    }
  }
  
  
  return(ret)
  
}



#' Function returns result from mcleod.CI.deconv.bank.get_median_curves_for_worst_case_hypothesis, and extract values at a specific point in the a.vec grid
#'
#' @param bank Passed to \code{mcleod.CI.deconv.bank.get_median_curves_for_worst_case_hypothesis}
#' @param ind_theta Passed to \code{mcleod.CI.deconv.bank.get_median_curves_for_worst_case_hypothesis}
#' @param ind_q Passed to \code{mcleod.CI.deconv.bank.get_median_curves_for_worst_case_hypothesis}
#' @param a_index the index in the a.grid for which posterior medians of CDFs are wanted.
#' @param nr.perms Passed to \code{mcleod.CI.deconv.bank.get_median_curves_for_worst_case_hypothesis}
#' @param is_GE Passed to \code{mcleod.CI.deconv.bank.get_median_curves_for_worst_case_hypothesis}
#' @param do_serial Passed to \code{mcleod.CI.deconv.bank.get_median_curves_for_worst_case_hypothesis}
#'
#' @return a vector of length \code{nr.perms}, with the median CDF values of different bootstrap permutations at a given point.
#' @export
#' @keywords internal
#' @examples
mcleod.CI.deconv.bank.get_median_curves_for_worst_case_hypothesis_at_point = function(bank,
                                                                                      ind_theta,
                                                                                      ind_q,
                                                                                      a_index,
                                                                                      nr.perms,
                                                                                      is_GE = T,
                                                                                      do_serial = F){
  
  #We get the required number of CDF median curves, from a WC LE/GE hypothesis, at grid point (ind_theta,ind_q)
  computed_curves_object = mcleod.CI.deconv.bank.get_median_curves_for_worst_case_hypothesis(bank = bank,
                                                                                             ind_theta = ind_theta,
                                                                                             ind_q = ind_q,
                                                                                             nr.curves = nr.perms,
                                                                                             is_GE = is_GE,
                                                                                             do_serial = do_serial)
  
  # we extract the values of the CDF median curves at the required point (given by index a_index)
  ret = unlist(lapply(computed_curves_object,FUN = function(x){x[a_index]}))
  return(ret)    
}




#' Function gives a lower bound for a CDF value, when testing a given LE/GE hypothesis
#' 
#' Function uses the binomial/noiseless approximation
#' 
#' @param bank bank object, used to extract the value of q by index of q.
#' @param ind_q index of q-value/CDF-value for the tested hypothesis
#' @param CDF_value The CDF value for which to compute a lower bound for the PV
#' @param is_GE is the hypothesis GE/LE
#'
#' @return lower bound for the PV, computed by the binomial approximation
#' @export
#' @keywords internal
#' @examples
mcleod.CI.lower_bound_PV_for_worst_case=function(bank,
                                                 ind_q,
                                                 CDF_value,
                                                 is_GE = F){
  
  # the q for the H0 for which a PV is computed is computed 
  current_q = bank$CI_param$q_vec[ind_q]
  n = length(bank$N_vec) #total number of tries
  t_value = n*CDF_value #total number of successes
  
  prob_at_t_value = 0
  
  #handle the two cases where n*CDF_value in an integer, and there is a probability mass to get the value at  t_value
  if(is_GE & t_value == round(t_value)){
    prob_at_t_value = dbinom(x = t_value,size = n,prob = current_q)
  }
  if(!is_GE & t_value == round(t_value)){
    prob_at_t_value = dbinom(x = n-t_value,size = n,prob = 1-current_q)
  }
  
  #add the probability for value greater/lower than t_value
  if(is_GE)
    return(pbinom(q = t_value,size = n,prob = current_q,lower.tail = F)+prob_at_t_value)
  return(pbinom(q = n-t_value,size = n,prob = 1-current_q,lower.tail = F)+prob_at_t_value)
}


#' Function computes PV for a given GE/LE hypothesis
#'
#' @param bank cache object to update and also use for computations. Also contains the CI_params object, which contains all computational and statistical parameters
#' @param ind_theta the index of the theta value, for the hypothesis to be tested
#' @param ind_q the index of the theta value, for the hypothesis to be tested
#' @param CDF_value the median CDF value for the test data, at the a_index point used for testing
#' @param a_index the index (in the a.grid) for which computation should be made. This value needs to be obtained using \code{mcleod.CI.find.ai.by.theta.and.rho}, using the theta corresponding to ind_theta, and the rho for the current tested hypothesis.
#' @param alpha the one sided significance level of testing. Will be used for the two fast checks specificed below
#' @param nr.perm number of permutations for PV computation
#' @param do_check_vs_noiseless_case Should a lower bound for the PV be computed using the noiseless case. If the lowerbound exceeds alpha, the reported PV is 1.
#' @param do_check_vs_minimum_number_of_required_iterations Should a quick check be performed using ceiling(alpha*nr.perm) hypotheses. If all bootstrap samples are more extreme than the sample, than we know we do not reject at level alpha. If this is the case, the function reports PV = 1.
#' @param is_GE is the hypothesis GE? (F = LE hypothesis)
#' @param do_serial should computation be done serially
#'
#' @return
#' @export
#' @keywords internal
#' @examples
mcleod.CI.PV.at_point = function(bank,
                                 ind_theta,
                                 ind_q,
                                 CDF_value,
                                 a_index,
                                 alpha = 0.05,
                                 nr.perm = 200,
                                 do_check_vs_noiseless_case = T,
                                 do_check_vs_minimum_number_of_required_iterations = T,
                                 is_GE = F,
                                 do_serial = F){
  
  # the (theta,q) for the WC hypothesis to be computed
  current_q = bank$CI_param$q_vec[ind_q]
  current_theta = bank$CI_param$theta_vec[ind_theta]
  n = length(bank$N_vec) #the number of samples
  
  ret = NA
  
  # if asked by the user, we check if it is even possible to reject the null hypothesis for the no-noise (binomial) case
  # if we cant reject for the no-noise case (infinite number of draws per observation), then we cant reject for the case with noise (finite number of draws for observations)
  if(do_check_vs_noiseless_case){
    ret = mcleod.CI.lower_bound_PV_for_worst_case(bank = bank,ind_q = ind_q,CDF_value = CDF_value,is_GE = is_GE)
    if(ret>=alpha){
      return(1) # we can just return 1, since the PV computed doesn't matter.
    }
  }
  
  #another possible check we can do, is run a small number of iterations (alpha*nr.perm) and check if all of them are more extreme than the data.
  # If (alpha*nr.perm) null samples are more extreme than the data, you know that the PV is > alpha for sure, no need to compute an exact Pvalue using nr.perm data generations.
  if(do_check_vs_minimum_number_of_required_iterations){
    minimal_required_number_of_iterations = ceiling(alpha*nr.perm)
    
    null_stat_values_for_quick_test = mcleod.CI.deconv.bank.get_median_curves_for_worst_case_hypothesis_at_point(bank,
                                                                                                                 ind_theta = ind_theta,
                                                                                                                 ind_q = ind_q,
                                                                                                                 a_index = a_index,
                                                                                                                 nr.perms = minimal_required_number_of_iterations,
                                                                                                                 is_GE = is_GE,
                                                                                                                 do_serial = do_serial)
    if(( is_GE & all(null_stat_values_for_quick_test >= CDF_value)) |
       (!is_GE & all(null_stat_values_for_quick_test <= CDF_value))){
      return(1)
    }
    
  }
  
  # no more checks - we compute full nr.perm data generations from the worst case hypothesis, and calculate the percentage of times
  # the test statistic (median CDF of data at theta +- rho) is more extreme the the values samples under the null hypothesis.
  
  null_stat_values = mcleod.CI.deconv.bank.get_median_curves_for_worst_case_hypothesis_at_point(bank,
                                                                                                ind_theta = ind_theta,
                                                                                                ind_q = ind_q,
                                                                                                a_index = a_index,
                                                                                                nr.perms = nr.perm,
                                                                                                is_GE = is_GE,
                                                                                                do_serial = do_serial)
  
  if(is_GE)
    return(mean(c(null_stat_values,CDF_value) >= CDF_value))
  return(mean(c(null_stat_values,CDF_value) <= CDF_value))
  
}

#' Compute the index on the a grid, for testing a specific LE/GE hypothesis
#'
#' For GE hypotheses, the a.grid point selected is the rightmost point smaller than theta-rho. For LE hypotheses, the a.grid point selected is the leftmost point bigger than theta+rho.
#' @param res_mcleod_object mcleod object. Used for extracting the a.vec grid
#' @param theta theta for the hypothesis
#' @param rho rho used for testing
#' @param is_GE is the hypothesis LE or GE
#'
#' @return index of the point on the a.vec grid, on which the test should be performed
#' @export
#' @keywords internal
mcleod.CI.find.ai.by.theta.and.rho=function(res_mcleod_object, theta, rho, is_GE = T){
  if(is_GE){
    # for a GE type hypothesis, we find the right most point, which is at least "rho distance" to the left of theta
    a_ind_GE = which(res_mcleod_object$parameters_list$a.vec <= theta - rho)
    if(length(a_ind_GE) > 0 ){ #if there is a point to consider
      a_ind_GE = max(a_ind_GE) #we take the rightmost one
    }else{
      a_ind_GE = 1 #if no points, take the leftmost side of the grid
    }
    return(a_ind_GE)
  }else{
    # for an LE type hypothesis, we find the left most point, which is at least "rho distance" to the right of theta
    a_ind_LE = which(res_mcleod_object$parameters_list$a.vec >= theta + rho)
    if(length(a_ind_LE) > 0 ){#if there is a point to consider
      a_ind_LE = min(a_ind_LE) #we take the leftmost one
    }else{
      a_ind_LE = length(res_mcleod_object$parameters_list$a.vec) #if no points, take the rightmost side of the grid
    }
    return(a_ind_LE)
  }
}

#' Function performs calibration for the value of rho used for testing (unless the user asked for a specific rho) 
#'
#' Calibration results returned as an object of a specific type
#' 
#' @param bank_original Cache object to be updated. Also contains CI_params containing required parameters and definitions.
#' @param res_mcleod_holdout mcleod result for the holdout data
#' @param CDF_holdout point estimates for the CDF (posterior median), obtained for the holdout data
#' @param alpha.one.sided significance level for one sided test
#' @param nr.perm number of bootstrap samples when testing
#' @param possible_rhos an ordered vector of the possible rhos to be considered
#' @param q_for_rho_optimization an ordered vector of CDF values, used to select the thetas for which optimization is performed (by looking at the thetas corresponding to these CDF values in CDF_holdout)
#' @param theta_for_rho_optimization if specified, thetas for which calibration is performed will be taken from this vector, instead of the ones defined by the CDF values given by \code{q_for_rho_optimization}
#' @param verbose should the function print messages
#'
#' @return an object of type 'mcleod.CI.obj.rho' with the following fields
#' \itemize{
#' \item{rho_approx_fun_LE}{ - BAR}
#' \item{rho_approx_fun_GE }{ - BAR}
#' \item{bank }{ - BAR}
#' \item{rho_approx_fun_LE_specific_non_smoothed }{ - BAR}
#' \item{rho_approx_fun_GE_specific_non_smoothed }{ - BAR}
#' \item{rho_approx_fun_LE_specific_smoothed }{ - BAR}
#' \item{rho_approx_fun_GE_specific_smoothed }{ - BAR}
#' \item{curve_LE_q_by_theta_and_rho }{ - BAR}
#' \item{curve_GE_q_by_theta_and_rho }{ - BAR}
#' \item{distances }{ - BAR}
#' \item{scores}{ - BAR}
#' \item{selected_rho}{ - BAR}
#' }
#' @export
#' @keywords internal
mcleod.CI.rho.calibration.constructor = function(
  bank_original,
  res_mcleod_holdout,
  CDF_holdout,
  alpha.one.sided,
  nr.perm = 200,
  possible_rhos = c(0.1,0.2,0.3,0.4,0.5),
  q_for_rho_optimization = c(0.2,0.4,0.6,0.8),
  theta_for_rho_optimization = NULL,
  verbose = F
){
  bank<<- bank_original #register the bank as a global object
  NR.POINTS.FOR.PV.EXTERPOLATION.IN.CALIBRATION = bank$CI_param$rho.calibration.nr.points.for.pv.exterpolation #number of points by which we compute an estimate of the CI at each point
  rho.calibration.method  = bank$CI_param$rho.calibration.method #either max/ sum / specific
  nr_theta_points_for_optimization = NA
  if(is.null(theta_for_rho_optimization)){ #if the user didnt ask for specific thethas for the optimization, we choose the theta points by the quantiles of the point estimate for the holdout data
    nr_theta_points_for_optimization = length(q_for_rho_optimization) #theta will be determined adaptively by q_for_rho_optimization
    calibration_points_by_q = T
  }else{
    nr_theta_points_for_optimization = length(theta_for_rho_optimization) #theats will be determined by the user input theta_for_rho_optimization
    calibration_points_by_q = F
  }
  
  #these will hold, for each theta point considered (by row), the estimated q-values of GE and LE curves, by rho (column)
  #using these matrices, we will minimize (min max, min sum, etc) the size of CIs for the holdout data, and select the optimal rho
  curve_GE_q_by_theta_and_rho = matrix(NA,nrow = nr_theta_points_for_optimization,ncol = length(possible_rhos))
  curve_LE_q_by_theta_and_rho = matrix(NA,nrow = nr_theta_points_for_optimization,ncol = length(possible_rhos))
  
  #these will hold the optimal rho by theta point. These will be useful when the user asks for mode 'specific' and we need to interpolate to find optimal rho as a function of theta (once for LE and once for GE)
  optimal_rho_by_theta_for_GE = rep(NA,nr_theta_points_for_optimization)
  optimal_rho_by_theta_for_LE = rep(NA,nr_theta_points_for_optimization)
  theta_points = rep(NA,nr_theta_points_for_optimization) #this will hold the values of theta, for which we calibrate rho
  
  for(index_q in 1:nr_theta_points_for_optimization){ #iterate over points in the theta axis
    
    if(calibration_points_by_q){ #if the user inserted wanted q-values
      current_q = q_for_rho_optimization[index_q] #the current q-value the user asked for.
      a_ind_for_theta_for_current_q = which.min(abs(CDF_holdout - current_q)) #we find the closest point in the deconvolution estimate for the holdout data which has CDF value close to current_q
      #then, we find the point in the theta grid defined by the user (which is coarser than the a grid) which is closest to a_ind_for_theta_for_current_q
      theta_current_q = res_mcleod_holdout$parameters_list$a.vec[a_ind_for_theta_for_current_q]
      theta_current_q_ind = which.min(abs(bank$CI_param$theta_vec - theta_current_q))
      theta_current_q = bank$CI_param$theta_vec[theta_current_q_ind]
      theta_points[index_q] = theta_current_q
      if(verbose)
        print(paste0('optimizing rho for q=',current_q,', which is equivalent to theta = ',theta_current_q,' in the holdout data'))
    }else{
      #the user has chosed a theta point. We just choose the closest one in the theta grid.
      theta_current_q_ind = which.min(abs(bank$CI_param$theta_vec - theta_for_rho_optimization[index_q]))
      theta_current_q = bank$CI_param$theta_vec[theta_current_q_ind]
      a_ind_for_theta_for_current_q = which.min(abs(res_mcleod_holdout$parameters_list$a.vec - theta_current_q))
      current_q = CDF_holdout[a_ind_for_theta_for_current_q]
      theta_points[index_q] = theta_current_q
      if(verbose)
        print(paste0('optimizing rho theta = ',theta_current_q,' in the holdout data'))
    }
   
    
    # we have finished figuring out on which thetas we compute CIs for q for the holdout data
    # we start with the lower end of CIs (determined by the GE hypothesis)
    
    q_lower_by_rho = rep(NA,length(possible_rhos)) #this will hold the estimated lower point of CI, for the current theta, for each possible value of rho
    #we can start testing GE hypotheses from this value of q (determined by the noiseless case):
    point_to_start_testing_GE = qbinom(p = alpha.one.sided,size = length(bank$N_vec),prob = current_q) / length(bank$N_vec)
    
    # than we find the NR.POINTS.FOR.PV.EXTERPOLATION.IN.CALIBRATION values of q which are smaller than point_to_start_testing_GE.
    points_to_test_GE = which(bank$CI_param$q_vec<= point_to_start_testing_GE)
    points_to_test_GE = tail(points_to_test_GE,n = NR.POINTS.FOR.PV.EXTERPOLATION.IN.CALIBRATION)
    
    # for each of the q-values in points_to_test_GE, we compute a PV value with each of the rhos.
    if(length(points_to_test_GE)>=2){
      if(verbose)
        print(paste0('selecting rho for GE'))
      for(index_rho in 1:length(possible_rhos)){ #iterate over rhos:
        
        current_rho = possible_rhos[index_rho]
        # find the point for computing the statistic, which is the rightmost point smaller than theta-rho
        a_ind_GE = mcleod.CI.find.ai.by.theta.and.rho(res_mcleod_object = res_mcleod_holdout,
                                                      theta = theta_current_q,
                                                      rho = current_rho,
                                                      is_GE = T)
        #next, we iterate over the NR.POINTS.FOR.PV.EXTERPOLATION.IN.CALIBRATION q-values found in points_to_test_GE and compute a Pvalue for each of them
        PVs_at_Qs = rep(NA,length(points_to_test_GE))
        
         q_lower_by_rho[index_rho] = 0
        for(i in length(points_to_test_GE):1){
          PVs_at_Qs[i] = mcleod.CI.PV.at_point(bank = bank,
                                               ind_theta = theta_current_q_ind,
                                               ind_q = points_to_test_GE[i],
                                               CDF_value = CDF_holdout[a_ind_GE],
                                               a_index = a_ind_GE,
                                               alpha = alpha.one.sided,
                                               nr.perm = nr.perm,
                                               do_check_vs_noiseless_case = F,
                                               do_check_vs_minimum_number_of_required_iterations = F,
                                               is_GE = T,
                                               do_serial = bank$CI_param$do_serial)
          
        }
        # 
        # we then create a linear model for the log-it of PVs as a function of q:
        if(length(unique(PVs_at_Qs))>1){
          PVs_at_Qs = PVs_at_Qs*(nr.perm)/(nr.perm+1) #this is to make sure we dont have 1's. 0's are avoided by adding the test statistic to the perms when computing a PV value
          logits = log.odds(PVs_at_Qs)
          model = lm(logits~bank$CI_param$q_vec[points_to_test_GE])
          b0 = model$coefficients[1]
          b1 = model$coefficients[2]
          q_lower_by_rho[index_rho] = (log.odds(alpha.one.sided) - b0 )/b1 #than we interpolate/exterpolate to find the lower point of the CI for q, at this combination of value for theta and rho.
        }else{
          #Nothing to do
        }
        
        if(q_lower_by_rho[index_rho]<0 | q_lower_by_rho[index_rho]>1){#by exterpolation or numerical instability
          q_lower_by_rho[index_rho] = 0
        }
         # for the current theta point and rho, we store the q-value of the lower end of the CI
        curve_GE_q_by_theta_and_rho[index_q,index_rho] = q_lower_by_rho[index_rho]
      }
      #for the current theta point specifically, we know the (index) of the optimal rho, by finding which rho had the highest value of the low-end of the CI
      optimal_rho_by_theta_for_GE[index_q] =  which.max(q_lower_by_rho) #will be used only if the user asked for method "specific"
    }
    
    #we redo the same analysis for the upper side of the CIs
    q_upper_by_rho = rep(NA,length(possible_rhos)) #this will hold the estimated upper point of CI, for the current theta, for each possible value of rho
    #we can start testing LE hypotheses from this value of q (determined by the noiseless case):
    point_to_start_testing_LE = qbinom(p = 1-alpha.one.sided,size = length(bank$N_vec),prob = current_q) / length(bank$N_vec)
    
    # than we find the NR.POINTS.FOR.PV.EXTERPOLATION.IN.CALIBRATION values of q which are higher than point_to_start_testing_GE.
    points_to_test_LE = which(bank$CI_param$q_vec>= point_to_start_testing_LE)
    points_to_test_LE = head(points_to_test_LE,n = NR.POINTS.FOR.PV.EXTERPOLATION.IN.CALIBRATION)
    
    # for each of the q-values in points_to_test_GE, we compute a PV value with each of the rhos.
    if(length(points_to_test_LE)>=2){
      if(verbose)
        print(paste0('selecting rho for LE'))
      for(index_rho in 1:length(possible_rhos)){
        
        current_rho = possible_rhos[index_rho]
        # find the point for computing the statistic, which is the leftmost point higher than theta+rho
        a_ind_LE = mcleod.CI.find.ai.by.theta.and.rho(res_mcleod_object = res_mcleod_holdout,
                                                      theta = theta_current_q,
                                                      rho = current_rho,
                                                      is_GE = F)
        
        q_upper_by_rho[index_rho] =  1
        
        #next, we iterate over the NR.POINTS.FOR.PV.EXTERPOLATION.IN.CALIBRATION q-values found in points_to_test_LE and compute a Pvalue for each of them
        PVs_at_Qs = rep(NA,length(points_to_test_LE))
        for(i in 1:length(points_to_test_LE)){
          PVs_at_Qs[i] = mcleod.CI.PV.at_point(bank = bank,
                                               ind_theta = theta_current_q_ind,
                                               ind_q = points_to_test_LE[i],
                                               CDF_value = CDF_holdout[a_ind_LE],
                                               a_index = a_ind_LE,
                                               alpha = alpha.one.sided,
                                               nr.perm = nr.perm,
                                               do_check_vs_noiseless_case = F,
                                               do_check_vs_minimum_number_of_required_iterations = F,
                                               is_GE = F,
                                               do_serial = bank$CI_param$do_serial)
         
        }
        
        #we then create a linear model for the log-it of PVs as a function of q:
        PVs_at_Qs = PVs_at_Qs*(nr.perm)/(nr.perm+1) #this is to make sure we dont have 1's. 0's are avoided by adding the test statistic to the perms when computing a PV value
        if(length(unique(PVs_at_Qs))>1){
          logits = log.odds(PVs_at_Qs)
          model = lm(logits~bank$CI_param$q_vec[points_to_test_LE])
          b0 = model$coefficients[1]
          b1 = model$coefficients[2]
          q_upper_by_rho[index_rho] = (log.odds(alpha.one.sided) - b0 )/b1 #than we interpolate/exterpolate to find the upper point of the CI for q, at this combination of value for theta and rho.
        }else{
          # Nothing to do
        }
        if(q_upper_by_rho[index_rho]<0 | q_upper_by_rho[index_rho]>1){ #by exterpolation or or numerical instability
          q_upper_by_rho[index_rho] = 1
        }
        # for the current theta point and rho, we store the q-value of the upper end of the CI
        curve_LE_q_by_theta_and_rho[index_q,index_rho] = q_upper_by_rho[index_rho]
      }
      #for the current theta point specifically, we know the (index) of the optimal rho, by finding which rho had the lowest value of the top-end of the CI
      optimal_rho_by_theta_for_LE[index_q] = which.min(q_upper_by_rho) #will be used only if the user asked for method "specific"
    }
    
  }# end of loop over q
  
  #the two matrices curve_LE_q_by_theta_and_rho and curve_GE_q_by_theta_and_rho are now filled
  # we proceed to compute the optimal rho according to the method that the user requested.
  
  #if we couldnt compute optimal rho for point (for method 'specific', than we fill values from the left (for LE), or from the right (for GE)).
  # the order of filling (left/right) is chosen so that   
  if(nr_theta_points_for_optimization>1){# check this is not a case we are handling confidence intervals
    for(i in 2:length(optimal_rho_by_theta_for_LE)){
      if(is.na(optimal_rho_by_theta_for_LE[i]))
        optimal_rho_by_theta_for_LE[i] = optimal_rho_by_theta_for_LE[i-1]
    }
    for(i in (length(optimal_rho_by_theta_for_GE)-1):1){
      if(is.na(optimal_rho_by_theta_for_GE[i]))
        optimal_rho_by_theta_for_GE[i] = optimal_rho_by_theta_for_GE[i+1]
    }  
  }
  
  #points that are still NA are placed as 0
  if(any(is.na(optimal_rho_by_theta_for_LE))){
    optimal_rho_by_theta_for_LE[is.na(optimal_rho_by_theta_for_LE)]=0
  }
  if(any(is.na(optimal_rho_by_theta_for_GE))){
    optimal_rho_by_theta_for_GE[is.na(optimal_rho_by_theta_for_GE)]=0
  }
  
  #we proceed to produce continuous function of optimal rho as a function of theta.
  # these functions will be used in practice only if the user chose 'specific'
  
  # we generate a data structure for optimization
  #pad the thetas with the grid edges, and the rhos with the edge values:
  optimal_rho_by_theta_for_LE = c(optimal_rho_by_theta_for_LE[1],
                                  optimal_rho_by_theta_for_LE,
                                  optimal_rho_by_theta_for_LE[length(optimal_rho_by_theta_for_LE)])
  optimal_rho_by_theta_for_GE = c(optimal_rho_by_theta_for_GE[1],
                                  optimal_rho_by_theta_for_GE,
                                  optimal_rho_by_theta_for_GE[length(optimal_rho_by_theta_for_GE)])
  
  optimal_rho_by_theta_for_LE = possible_rhos[optimal_rho_by_theta_for_LE]
  optimal_rho_by_theta_for_GE = possible_rhos[optimal_rho_by_theta_for_GE]
  theta_points = c(min(bank$CI_param$theta_vec),
                   theta_points,
                   max(bank$CI_param$theta_vec))
  
  # produce a continuous function for optimal rho
  if(nr_theta_points_for_optimization>1){
    x.ks = seq(min(theta_points),max(theta_points),(max(theta_points) - min(theta_points))/1000)
    optimal_rho_by_theta_for_LE_smoothed = ksmooth(x = theta_points,
                                                   y = optimal_rho_by_theta_for_LE,
                                                   x.points = x.ks,
                                                   kernel = 'normal',bandwidth = 1)
    optimal_rho_by_theta_for_GE_smoothed = ksmooth(x = theta_points,
                                                   y = optimal_rho_by_theta_for_GE,
                                                   x.points = x.ks,
                                                   kernel = 'normal',bandwidth = 1)
    
  }else{# if nr_theta_points_for_optimization=1, we cannot interpolate, and we produce a function which is a constant.
    optimal_rho_by_theta_for_LE_smoothed = list(x = c(theta_points-1,theta_points+1), y = rep(optimal_rho_by_theta_for_LE,2))
    optimal_rho_by_theta_for_GE_smoothed = list(x = c(theta_points-1,theta_points+1), y = rep(optimal_rho_by_theta_for_GE,2))
    
  }
  
  #pack the results from smoothing as a function (approxfun helps with that)
  rho_approx_fun_LE = approxfun(x = optimal_rho_by_theta_for_LE_smoothed$x,y = optimal_rho_by_theta_for_LE_smoothed$y,
                                method = 'linear',rule = 2)
  rho_approx_fun_GE = approxfun(x = optimal_rho_by_theta_for_GE_smoothed$x,y = optimal_rho_by_theta_for_GE_smoothed$y,
                                method = 'linear',rule = 2)
  
  #pack also the non-smoohted results as a function (with linear interpolation across theta between the optimal rhos)
  if(nr_theta_points_for_optimization>1){
    
    rho_approx_fun_LE_non_smoothed = approxfun(x = theta_points,y = optimal_rho_by_theta_for_LE,method = 'linear',rule = 2)
    rho_approx_fun_GE_non_smoothed = approxfun(x = theta_points,y = optimal_rho_by_theta_for_GE,method = 'linear',rule = 2)

  }else{
    rho_approx_fun_LE_non_smoothed = optimal_rho_by_theta_for_LE_smoothed
    rho_approx_fun_GE_non_smoothed = optimal_rho_by_theta_for_GE_smoothed
  }
  
  rho_approx_fun_LE = rho_approx_fun_LE_non_smoothed  #our reccomended approach is the non-smoothed function, but we also report the smoothed function
  rho_approx_fun_GE = rho_approx_fun_GE_non_smoothed
  

  is_single_rho_method = (rho.calibration.method %in% c('max','sum')) #handle cases where the user asked for a single rho for all values of theta and LE/GE
  if(is_single_rho_method){
    #we compute a score, by either the sum or max of CI lengths across thetas
    # we choose rho to be arg min (sum/max (CI Length)).
    distances = curve_LE_q_by_theta_and_rho - curve_GE_q_by_theta_and_rho
    if(rho.calibration.method == 'max'){
      scores = apply(distances,2,max,na.rm = T)
    }else if(rho.calibration.method == 'sum'){
      scores = apply(distances,2,sum,na.rm = T)
    }
    selected_rho = possible_rhos[which.min(scores)]
    rho_approx_fun_LE = function(x){return(selected_rho)} #we pack the results using a function the returns a constant value
    rho_approx_fun_GE = rho_approx_fun_LE
  }
  
  #  pack results
  ret = list(rho_approx_fun_LE = rho_approx_fun_LE,#rho_approx_fun_LE,
             rho_approx_fun_GE = rho_approx_fun_GE,#rho_approx_fun_GE,
             bank = bank,
             rho_approx_fun_LE_specific_non_smoothed = rho_approx_fun_LE_non_smoothed,
             rho_approx_fun_GE_specific_non_smoothed = rho_approx_fun_GE_non_smoothed,
             rho_approx_fun_LE_specific_smoothed = rho_approx_fun_LE,
             rho_approx_fun_GE_specific_smoothed = rho_approx_fun_GE,
             curve_LE_q_by_theta_and_rho = curve_LE_q_by_theta_and_rho,
             curve_GE_q_by_theta_and_rho = curve_GE_q_by_theta_and_rho
             )
  # for single rho methods we also have scores to report
  if(is_single_rho_method){
    ret$distances = distances
    ret$scores = scores
    ret$selected_rho = selected_rho
  }
  class(ret) = CLASS.NAME.MCLEOD.CI.RHO
  return(ret)
}



#' Compute PVs for all GE/LE hypotheses on the theta X q grid
#'
#' @param bank_original cache to be updated and used, also contains parameters
#' @param rho_calibration_obj rho calibration object
#' @param res_mcleod_data result of \code{mcleod} for the test data
#' @param median_curve posterior median CDF for the test data
#' @param alpha.one.sided alpha for one-sided testing
#' @param verbose should the function print messages
#'
#' @return a list with the following entries: \code{GE.pval.grid} - matrix with PVs for GE hypotheses. theta and q for the hypotheses are found in the colnames and rownames; \code{LE.pval.grid}- similar to \code{GE.pval.grid}, only for LE type hypotheses ; \code{bank} - updated cache
#' @export
#' @keywords internal
compute_P_values_over_grid_function=function(bank_original,rho_calibration_obj,res_mcleod_data,median_curve,alpha.one.sided,verbose = F){
  bank<<- bank_original #set as public variable
  
  #Two grids of Pvalues, for LE/GE pvalues
  GE.pval.grid = matrix(NA,ncol = bank$CI_param$n_theta,nrow = bank$CI_param$n_q,
                        dimnames = list(paste0('q = ',bank$CI_param$q_vec),paste0('theta = ',bank$CI_param$theta_vec)))
  LE.pval.grid = matrix(NA,ncol = bank$CI_param$n_theta,nrow = bank$CI_param$n_q,
                        dimnames = list(paste0('q = ',bank$CI_param$q_vec),paste0('theta = ',bank$CI_param$theta_vec)))
  
  
  #Compute GE Grid:
  P_values_grid_compute_univariate_CI = bank$CI_param$P_values_grid_compute_univariate_CI #This is an indicator used by the package to denote we are computing a CI for a single q or theta.
  
  CI_for_single_Q_need_to_break = F
  
  for(j in 1:bank$CI_param$n_theta){
    for(i in (bank$CI_param$n_q):1){
      
      if(!(bank$CI_param$theta_vec[j] %in% bank$CI_param$theta_vec_for_computation & #this condition makes sure we iterate over the entire grid put compute only wanted values. This is used primarily for CIs for single q/theta
           bank$CI_param$q_vec[i] %in% bank$CI_param$q_vec_for_computation)){
        next
      }
      
      if(verbose)
        print(paste0('testing GE at q_ind = ',i,'/',bank$CI_param$n_q,' , theta_ind = ',j,'/',bank$CI_param$n_theta))
      rho_GE = rho_calibration_obj$rho_approx_fun_GE(bank$CI_param$theta_vec[j]) #get the rho
      
      
      #get the point for the statistic
      a_ind_GE = mcleod.CI.find.ai.by.theta.and.rho(res_mcleod_object = res_mcleod_data,
                                                    theta = bank$CI_param$theta_vec[j],
                                                    rho = rho_GE,
                                                    is_GE = T)
      #compute pvalues
      GE.pval.grid[i,j] = mcleod.CI.PV.at_point(bank = bank,
                                                ind_theta = j,
                                                ind_q = i,
                                                CDF_value = median_curve[a_ind_GE],
                                                a_index = a_ind_GE,
                                                alpha = alpha.one.sided,
                                                nr.perm = bank$CI_param$nr.perms,
                                                do_check_vs_noiseless_case = T,
                                                do_check_vs_minimum_number_of_required_iterations = T,
                                                is_GE = T,
                                                do_serial = bank$CI_param$do_serial)
      
      #check if we can break the loop. This is for the case we have a single CI, and we found its edge
      if(P_values_grid_compute_univariate_CI & GE.pval.grid[i,j]<=alpha.one.sided){
        if(length(bank$CI_param$q_vec_for_computation) == 1)
          CI_for_single_Q_need_to_break = T
        
        break
      }

    }#end of loop over q's
    
    if(CI_for_single_Q_need_to_break)
      break
    
  }# end of loop over theta's
    
  
  #Compute LE Grid:
  CI_for_single_Q_need_to_break = F
  for(j in (bank$CI_param$n_theta):1){
    for(i in 1:bank$CI_param$n_q){
      #this loop has the same structure as the above loop, see extensive comments there
      
      if(!(bank$CI_param$theta_vec[j] %in% bank$CI_param$theta_vec_for_computation &
           bank$CI_param$q_vec[i] %in% bank$CI_param$q_vec_for_computation)){
        next
      }
      
      if(verbose)
        print(paste0('testing LE at q_ind = ',i,'/',bank$CI_param$n_q,
                     ' , theta_ind = ',j,'/',bank$CI_param$n_theta))
      
      
      rho_LE = rho_calibration_obj$rho_approx_fun_LE(bank$CI_param$theta_vec[j])
      
      a_ind_LE = mcleod.CI.find.ai.by.theta.and.rho(res_mcleod_object = res_mcleod_data,
                                                    theta = bank$CI_param$theta_vec[j],
                                                    rho = rho_LE,
                                                    is_GE = F)
      
      
      LE.pval.grid[i,j] = mcleod.CI.PV.at_point(bank = bank,
                                                ind_theta = j,
                                                ind_q = i,
                                                CDF_value = median_curve[a_ind_LE],
                                                a_index = a_ind_LE,
                                                alpha = alpha.one.sided,
                                                nr.perm = bank$CI_param$nr.perms,
                                                do_check_vs_noiseless_case = T,
                                                do_check_vs_minimum_number_of_required_iterations = T,
                                                is_GE = F,
                                                do_serial = bank$CI_param$do_serial)
      
      if(P_values_grid_compute_univariate_CI & LE.pval.grid[i,j]<=alpha.one.sided){
        if(length(bank$CI_param$q_vec_for_computation) == 1)
          CI_for_single_Q_need_to_break = T
        
        break
      }
        
      
    }#end of loop of over q's  
    
    
    if(CI_for_single_Q_need_to_break)
      break
    
    
  }#end of loop over thetas
  
  
  ret = list()
  ret$GE.pval.grid = GE.pval.grid
  ret$LE.pval.grid = LE.pval.grid
  ret$bank = bank
  return(ret)
}


#' Function performs efficient computation of pointwise CIs, for a given confidence level
#'
#' @param bank_original 
#' @param res_mcleod_data 
#' @param rho_calibration_obj 
#' @param median_curve 
#' @param alpha.one.sided 
#' @param verbose 
#'
#' @return a list with the following entries: \code{q_star_LE} - ; \code{q_star_GE} - ; \code{bank} - 
#' @export
#' @keywords internal
compute_CI_curves_function = function(
  bank_original,
  res_mcleod_data ,
  rho_calibration_obj,
  median_curve,
  alpha.one.sided,
  verbose
){
  bank<<- bank_original #set as global variable
  maximal_point_for_GE = rep(NA, bank$CI_param$n_theta) #these two arrays will hold, for each index/point in theta, the index for the q-value from which it is relevant to start checking the q-values for significance
  minimal_point_for_LE = rep(NA, bank$CI_param$n_theta)
  for(i in 1:bank$CI_param$n_theta){
    current_theta = bank$CI_param$theta_vec[i] #for each theta
    ai_point_GE = min(which(res_mcleod_data$parameters_list$a.vec >= current_theta)) #find the points for the statistics LE/GE
    ai_point_LE = max(which(res_mcleod_data$parameters_list$a.vec <= current_theta))
    maximal_point_for_GE[i] = max(which(bank$CI_param$q_vec<=median_curve[ai_point_GE]),1) # find the first q-values that are above/below the median CDF
    minimal_point_for_LE[i] = min(which(bank$CI_param$q_vec>=median_curve[ai_point_LE]),bank$CI_param$n_q)
  }
  
  i_star_GE = rep(NA,bank$CI_param$n_theta)
  q_star_GE = rep(NA,bank$CI_param$n_theta)
  for(i in 1:bank$CI_param$n_theta){
    #we start constructing the lower end of CI curves, by computing PVs for GE tests
    if(verbose){
      print(paste0('Computing GE confidence intervals, log.odds = ',bank$CI_param$theta_vec[i]))
    }
    
    if(i == 1){ #at the left we start from the bottom
      N_21_GE = 1
    }else{ #at later points (to the right), we start from the CI of the previous point +1, or the maximum ind for q
      N_21_GE = min(i_star_GE[i-1] + 1,bank$CI_param$n_q)
    }
    N_22_GE = maximal_point_for_GE[i]
    
    #get rho and the point for the statistic
    rho_GE = rho_calibration_obj$rho_approx_fun_GE(bank$CI_param$theta_vec[i])
    
    
    a_ind_GE = mcleod.CI.find.ai.by.theta.and.rho(res_mcleod_object = res_mcleod_data,
                                                  theta = bank$CI_param$theta_vec[i],
                                                  rho = rho_GE,
                                                  is_GE = T)
    #find the points we need to test over
    ind_to_select_from = (max(N_21_GE,1)):N_22_GE
    rejected_ind = rep(NA,length(ind_to_select_from))
    for(u in 1:length(rejected_ind)){ #starting from the bottom up, we test the points
      if(verbose){
        #print(paste0('Testing at q with index ',ind_to_select_from[u],' which is equivalent to ',bank$CI_param$q_vec[ind_to_select_from[u]]))
      }
      rejected_ind[u] = mcleod.CI.PV.at_point(bank = bank,
                                              ind_theta = i,
                                              ind_q = ind_to_select_from[u],
                                              CDF_value = median_curve[a_ind_GE],
                                              a_index = a_ind_GE,
                                              alpha = alpha.one.sided,
                                              nr.perm = bank$CI_param$nr.perms,
                                              do_check_vs_noiseless_case = T,
                                              do_check_vs_minimum_number_of_required_iterations = T,
                                              is_GE = T,
                                              do_serial = bank$CI_param$do_serial) <= alpha.one.sided #we check if we rejected
      if(is.na(rejected_ind[u])) #in case a pvalue cannot be computed, assume we did not reject
        rejected_ind[u] = F  
      
      # if(u==1 & rejected_ind[u] == F ){
      #   rejected_ind = rep(F,length(ind_to_select_from))
      #   break
      # }
      if(!rejected_ind[u]) #if we didn't reject, we can stop. We have found the lower edge of the CI for this value of theta
        break
      
    }
    
    #the next few lines hnde the index and value of q, by which rejection happened, so we can start at the next theta index from an updated q-level
    if(i == 1 & rejected_ind[1] == F){
      i_star_GE[i] = 0
    }else if (i == 1){
      i_star_GE[i] = ind_to_select_from[max(which(rejected_ind))]
    }
    
    if(i >1 & rejected_ind[1] == F){
      i_star_GE[i] = i_star_GE[i-1]
    }else if (i >1){
      i_star_GE[i] = ind_to_select_from[max(which(rejected_ind))]
    }
    if(i_star_GE[i] == 0){
      q_star_GE[i] = 0  
    }else{
      q_star_GE[i] = bank$CI_param$q_vec[i_star_GE[i]]   
    }
    
  }
  
  # NOTE: This code uses LE tests to find the upper part of the CI. it is similar to the above section, see extensive remarks in the previous section.
  i_star_LE = rep(NA,bank$CI_param$n_theta)
  q_star_LE = rep(NA,bank$CI_param$n_theta)
  for(i in bank$CI_param$n_theta:1){
    if(verbose){
      print(paste0('Computing LE confidence intervals, log.odds = ',bank$CI_param$theta_vec[i]))
    }
    if(i == bank$CI_param$n_theta){
      N_21_LE = bank$CI_param$n_q
    }else{
      N_21_LE = max(i_star_LE[i+1] - 1,1)
    }
    N_22_LE = minimal_point_for_LE[i]
    
    rho_LE = rho_calibration_obj$rho_approx_fun_LE(bank$CI_param$theta_vec[i])
    
    a_ind_LE = mcleod.CI.find.ai.by.theta.and.rho(res_mcleod_object = res_mcleod_data,
                                                  theta =  bank$CI_param$theta_vec[i],
                                                  rho = rho_LE,
                                                  is_GE = F)
    
    ind_to_select_from = N_22_LE:N_21_LE 
    
    rejected_ind = rep(NA,length(ind_to_select_from))
    
    for(u in length(ind_to_select_from):1){
      if(verbose){
        #print(paste0('Testing at q with index ',ind_to_select_from[u],' which is equivalent to ',bank$CI_param$q_vec[ind_to_select_from[u]]))
      }
      rejected_ind[u] = mcleod.CI.PV.at_point(bank = bank,
                                              ind_theta = i,
                                              ind_q = ind_to_select_from[u],
                                              CDF_value = median_curve[a_ind_LE],
                                              a_index = a_ind_LE,
                                              alpha = alpha.one.sided,
                                              nr.perm = bank$CI_param$nr.perms,
                                              do_check_vs_noiseless_case = T,
                                              do_check_vs_minimum_number_of_required_iterations = T,
                                              is_GE = F,
                                              do_serial = bank$CI_param$do_serial) <= alpha.one.sided
      
      if(is.na(rejected_ind[u])) #need to handle bounds and shifts better
        rejected_ind[u] = F
     
      if(!rejected_ind[u])
         break
    }
    
    if(i ==  bank$CI_param$n_theta & rejected_ind[length(rejected_ind)] == F){
      i_star_LE[i] = bank$CI_param$n_q+1
    }else if (i == bank$CI_param$n_theta){
      i_star_LE[i] = ind_to_select_from[min(which(rejected_ind))]
    }
    
    if(i < bank$CI_param$n_theta & rejected_ind[length(rejected_ind)] == F){
      i_star_LE[i] = i_star_LE[i+1]
    }else if (i < bank$CI_param$n_theta){
      i_star_LE[i] = ind_to_select_from[min(which(rejected_ind))]
    }
    
    if(i_star_LE[i] == bank$CI_param$n_q+1){
      q_star_LE[i] = 1  
    }else{
      q_star_LE[i] = bank$CI_param$q_vec[i_star_LE[i]]   
    }
    
  }
  #report q_star_LE and q_star_GE, toghether with the bank. The first two variables hold the CIs
  names(q_star_LE) = paste0('theta = ',bank$CI_param$theta_vec)
  names(q_star_GE) = paste0('theta = ',bank$CI_param$theta_vec)
  ret = list()
  ret$q_star_LE = q_star_LE
  ret$q_star_GE = q_star_GE
  ret$bank = bank
  return(ret)
}



#' Compute point-wise Confidence Intervals for the quantiles and percentiles of the mixing distribution of binomial samples.
#' 
#' The assumed model is of the form \eqn{Xi ~ bin(Ni,Pi)}, where \eqn{i} is an index in the range 1,...,n. The function constructs pointwise confidence intervals for the mixing distribution, i.e., the distribution of Pi's, for different quantiles and percentiles. The statistical method is explained in the package vignette. 
#' 
#' @details See package vignette for a full explanation on algorithm and parameters.
#' 
#' @param X Number of successful draws per observation
#' @param N Number of draws per observation
#' @param CI_param Result of function \code{\link{mcleod.CI.estimation.parameters}}, setting statistical and computational parameters. If you are unsure about the parameters, best to use the default option.
#' @param ratio_holdout When estimating rho adaptively from the data, the ratio of data samples used for the calibration procedure for rho. Values such as 0.1 and 0.2 are plausible.
#' @param compute_P_values_over_grid Should the function perform an exhaustive computation of the point-wise CIs, for different quantiles and percentiles of the mixing distribution. This is done by testing all LE/GE type hypotheses, see additional information in the package vignette and paper for the method. Generally, this option is not needed, and the user needs the efficient computation method which only constructs CI at a given confidence levels. This option is useful if a user wishes to construct CI for the mixing distribution at multiple levels simultanously (i.e., using results from a single function call).
#' @param compute_CI_curves Should the function perform an efficient computation of the point-wise CIs, for different quantiles and percentiles of the mixing distribution. This option is needed for most cases: get point-wise CIs for the mixing distribution at a given confidence levels, plot the CIs, etc.
#' @param verbose Should messages be printed to screen.
#' @param Use_Existing_Permutations_From_Object An existing object generated using mcleod.estimate.CI. The cache of CDF samples (used for computing PVs) is instantiated using the CDF samples available in this object. This helps speed up computations considerably. NOTE: It is up to the user to verify the the object uses the same CI parameters and N vec. If the used CDF samples (from WC hypothesis tests) were computed CI.params and N.vec different from the ones in the data, the results might be meaningless!
#'
#' @return A list set as class 'mcleod.CI.obj' with the following entries:
#' \itemize{
#' \item{pvalues_grid}{ - available if compute_P_values_over_grid is set to True. Contains a list with entries as detailed below. }
#' \item{computed_curves}{ - available if compute_CI_curves is set to True. Contains a list with entries as detailed below.}
#' \item{bank}{ - results of the internal function \code{\link{mcleod.CI.deconv.bank.constructor}}. This object serves as a cache storing estimated CDF of the mixing distribution, from bootstrap data samples used for estimating P.values. See more information in the package vignette. When running the function on similar inputs (having the same value of N.vec and the same CI params) this object can used to speed up PV computations, see description for above parameter \code{Use_Existing_Permutations_From_Object} }
#' \item{rho_calibration_obj}{ - result of internal function \code{\link{mcleod.CI.rho.calibration.constructor}}. Contains information on how rho was set adaptively for the data.}
#' \item{n_holdout}{ - When splitting the data, in order to choose rho adaptively, this is the number of samples taken from the full data and used for calibration.}
#' \item{X_rho}{ - number of successfull draws, for the part of the data used for calibrating rho. A subset of X}
#' \item{N_rho}{ - number of draws, for the part of the data used for calibrating rho. A subset of N, corresponding to \code{X_rho}}
#' \item{X_test}{ - number of successfull draws, for the part of the data used for testing. The remainder of X, after excluding \code{X_rho}}
#' \item{N_test}{ - number of draws, for the part of the data used for testing. The remainder of N, after excluding \code{N_rho}}
#' \item{res_mcleod_holdout}{ - result of \code{\link{mcleod}} run on the holdout data, used for calibrating rho.}
#' \item{CDF_holdout}{ - Values of the estimated CDF for mixture distribution in the holdout data (used for calibrating rho). The estimator for the mixing distribution is the pointwise (by theta) median of the posterior distribution. The theta values (X-axis) for the CDF are given by res_mcleod_holdout$parameters_list$a.vec}
#' \item{res_mcleod_data}{ - result of \code{\link{mcleod}} run on the test data. }
#' \item{CDF_data}{ - Values of the estimated CDF for mixture distribution in the test data. The estimator for the mixing distribution is the pointwise (by theta) median of the posterior distribution. The theta values (X-axis) for the CDF are given by res_mcleod_data$parameters_list$a.vec}
#' \item{ind_selected_for_test}{ - When splitting the data (due to using part of the data for calibrating rho), these are the indices (in terms of the input, X and N) of the samples used for testing.}
#' }
#' 
#' The list given by \code{computed_curves} contains the following entries:
#' \itemize{
#' \item{q_star_LE}{ - The upper end of pointwise CDFs for the mixing distribution, by value of theta. Values of theta are given in the vector entry names.}
#' \item{q_star_GE}{ - The lower end of pointwise CDFs for the mixing distribution, by value of theta. Values of theta are given in the vector entrynames.}
#' }
#' 
#' The list given by \code{pvalues_grid}
#' \itemize{
#' \item{GE.pval.grid}{ - Contains the PVs for GE type hypotheses. Coordinate by q and theta are given by column and row names.}
#' \item{LE.pval.grid}{ - Contains the PVs for LE type hypotheses. Coordinate by q and theta are given by column and row names.}
#' }
#' @export
#'
#' @examples
#' See package vignette
mcleod.estimate.CI = function(X,
                              N,
                              CI_param = mcleod.CI.estimation.parameters(),
                              ratio_holdout = 0.1,
                              compute_P_values_over_grid = F,
                              compute_CI_curves = T,
                              verbose = T,
                              Use_Existing_Permutations_From_Object = NULL ){
  
  # load libraries (they are suggested and not required)
  library(doRNG)
  library(doParallel)
  library(parallel)
  library(hash)
  
  #perform checks on parameters
  
  if(class(CI_param) != CLASS.NAME.MCLEOD.CI.PARAMETERS){
    stop('CI_param must be a result returned from mcleod.CI.estimation.parameters(...)')
  }
  
  if(ratio_holdout>1 | ratio_holdout<0)
    stop('ratio_holdout must be strictly between 0 and 1')
  
  if(!is.logical(compute_P_values_over_grid))
    stop('compute_P_values_over_grid must be logical variable')
  
  if(!is.logical(compute_CI_curves))
    stop('compute_CI_curves must be logical variable')
  
  if(!is.logical(verbose))
    stop('verbose must be a logical variable')
  
  if(compute_CI_curves & compute_P_values_over_grid)
    warning('generally you need only one of compute_CI_curves and compute_P_values_over_grid to be set to true, please make sure function parameters are specificed correctly. ')
  
  if(!compute_CI_curves & !compute_P_values_over_grid)
    warning('generally you need at least one of compute_CI_curves and compute_P_values_over_grid to be set to true, please make sure function parameters are specificed correctly. ')
  
  if(!is.null(Use_Existing_Permutations_From_Object ))
    if(class(Use_Existing_Permutations_From_Object) != CLASS.NAME.MCLEOD.CI)
      stop('Use_Existing_Permutations_From_Object must be a result of mcleod.estimate.CI()')
  
  if(!is.null(Use_Existing_Permutations_From_Object)){
    warning('Use_Existing_Permutations_From_Object was set to a non null value: note that you must use an object constructed using the same CI.parameters file, and having the same value of N')
  }
  
  ret = list() #returned results will go here
  
  
  alpha.one.sided = (1-CI_param$alpha.CI)/2 #one sided alpha, used for tests
  
  # if the user supplied a fixed value of rho, we  use it, and there is no need to split the data.
  # else, we perform a data split (the first case)
  if(is.na(CI_param$rho.set.value)){
    n_holdout = ceiling(ratio_holdout * length(X))
    ind_selected_for_test = sample(1:length(X),size = length(X)-n_holdout,replace = F)
    X_rho = X[1:n_holdout]; N_rho = N[1:n_holdout]
    X_test = X[-(1:n_holdout)]; N_test = N[-(1:n_holdout)]
  }else{
    n_holdout = 0
    X_rho = NA; N_rho = NA
    X_test = X; N_test = N
    ind_selected_for_test = 1:length(X)
  }
  
  #generate a bank, using the nr.draws of the test set, parameters, and previous permutations if available
  bank <<- mcleod.CI.deconv.bank.constructor(N_test,CI_param,Use_Existing_Permutations_From_Object)
  
  # perform deconvolution for the test data
  res_mcleod_data = mcleod(x.smp = X_test,n.smp =N_test,
                           a.limits = bank$CI_param$a.limits,
                           computational_parameters = bank$CI_param$comp_parameters,
                           prior_parameters = bank$CI_param$prior_parameters,
                           exact.numeric.integration = T)
  
  #compute the median of the posterior CDF for the data 
  median_curve = compute_medians_curve(res_mcleod_data)
  
  #Part I: functions for generating P_k_i based on precomputed values:
  Use_P_k_i_generator = F #currently this mechanism is disabled, since the generation of matrices is slower compared to numerical integration. We need to move parts of the generation to C code in order to speed them up.
  if(Use_P_k_i_generator){
    if(verbose){
      print(paste0('Starting construction of P_k_i generator'))
      start = Sys.time()
      
      gen_object = generate_P_k_i_matrix_cache(N,
                                               max(bank$CI_param$a.limits),
                                               CI_param$prior_parameters,
                                               CI_param$comp_parameters)
      gen_object$a.vec = res_mcleod_data$parameters_list$a.vec
      bank$gen_object = gen_object
      end = Sys.time()
      print(paste0('Ending construction of P_k_i generator'))
      print(end-start)
      
    }
  }

  cl <- NULL
  if(!CI_param$do_serial & !WORK_WITH_THREADS){ #if computation is not serial, and we are working with processes, we are working the doRNG
    cluster_type = 'PSOCK' #windows has only PSOCK
    if(Sys.info()['sysname']!='Windows')
      cluster_type = 'FORK' #however mac and linux have 'FORK' based clusters, which are faster!
    cl <- makeCluster(CI_param$nr.cores,type = cluster_type,setup_strategy = 'parallel') # we generate the cluster. All computations will be done with this cluster.
    registerDoParallel(cl)
  }
  
  
  #if rho isn't given by the user, we run a calibration procedure
  if(is.na(CI_param$rho.set.value)){
    #we perform deconvolution for the holdout data
    res_mcleod_holdout = mcleod(x.smp = X_rho,n.smp =N_rho,
                                a.limits = bank$CI_param$a.limits,
                                computational_parameters = bank$CI_param$comp_parameters,
                                prior_parameters = bank$CI_param$prior_parameters,
                                exact.numeric.integration = T)
    
    CDF_holdout = compute_medians_curve(res_mcleod_holdout)
    
    #we run the calbration proceudre. All parameters are found in CI.params and given by the user.
    start.time = Sys.time()
    rho_calibration_obj = mcleod.CI.rho.calibration.constructor(bank_original = bank,
                                                                res_mcleod_holdout = res_mcleod_holdout,
                                                                CDF_holdout = CDF_holdout,
                                                                alpha.one.sided = (1-CI_param$rho.alpha.CI)/2,
                                                                verbose = verbose,
                                                                nr.perm = CI_param$rho.estimation.perm,
                                                                possible_rhos = CI_param$rho.possible.values,
                                                                q_for_rho_optimization = CI_param$rho.q_for_calibration,
                                                                theta_for_rho_optimization = CI_param$rho.theta_for_calibration)
    end.time = Sys.time()
    rho_calibration_obj$Elapsed_time = end.time-start.time
    bank <<- rho_calibration_obj$bank #after computation has ended, we return update the bank for next function, using the bank returned from this function
    rho_calibration_obj$bank <- NULL #erase the bank inside the object so it doesnt take space
    if(verbose){
      print('rho calibration time')
      print(end.time-start.time)  
    }
    
    
  }else{ #if rho was set manually, we generate functions that return a constant value of rho
    if(verbose){
      print(paste0('rho set manually to ',CI_param$rho.set.value))
    }
    res_mcleod_holdout = NA
    CDF_holdout = NA
    rho_calibration_obj = list()
    theta_points = c(min(CI_param$theta_vec),
                     0,
                     max(CI_param$theta_vec))
    
    rho_approx_fun_LE = approxfun(x = theta_points,
                                  y = rep(CI_param$rho.set.value,3),
                                  method = 'linear',rule = 2)
    rho_approx_fun_GE = approxfun(x = theta_points,
                                  y = rep(CI_param$rho.set.value,3),
                                  method = 'linear',rule = 2)
    rho_calibration_obj = list(rho_approx_fun_LE = rho_approx_fun_LE,
                               rho_approx_fun_GE = rho_approx_fun_GE,
                               bank = bank)
    class(rho_calibration_obj) = CLASS.NAME.MCLEOD.CI.RHO
  }
  
  #in case the user requested to compute P-value across the entire grid
  if(compute_P_values_over_grid){
    start.time = Sys.time()
    
    # the results from computation
    pvalues_grid = compute_P_values_over_grid_function(
      bank_original = bank,
      rho_calibration_obj = rho_calibration_obj,
      res_mcleod_data = res_mcleod_data,
      median_curve = median_curve,
      alpha.one.sided = alpha.one.sided,
      verbose = verbose)
    
    
    
    end.time = Sys.time()
    pvalues_grid$Elapsed_time = end.time-start.time
    bank <<- pvalues_grid$bank #after computation has ended, we return update the bank for next function, using the bank returned from this function
    pvalues_grid$bank <- NULL #and erase the bank inside the object, so it doesnt take space
    ret$pvalues_grid = pvalues_grid
    if(verbose){
      print('time for computing pvalues over grid of hypotheses')
      print(end.time-start.time)  
    }
    
  }
  
  
  #in case the user requested to compute the CI curves (upper and lower)
  if(compute_CI_curves){
    start.time = Sys.time()
    computed_curves = compute_CI_curves_function(
      bank_original = bank,
      res_mcleod_data = res_mcleod_data,
      rho_calibration_obj = rho_calibration_obj,
      median_curve = median_curve,
      alpha.one.sided = alpha.one.sided,
      verbose = verbose
    )
    end.time = Sys.time()
    computed_curves$Elapsed_time = end.time-start.time
    bank <<- computed_curves$bank #after computation has ended, we return update the bank for next function, using the bank returned from this function
    computed_curves$bank <- NULL #and erase the bank inside the object, so it doesnt take space
    ret$computed_curves = computed_curves
    if(verbose){
      print('time for computing CI curves ')
      print(end.time-start.time)  
    }
  }
  
  #return results
  ret$bank = bank
  ret$rho_calibration_obj = rho_calibration_obj
  ret$n_holdout = n_holdout
  
  ret$X_rho = X_rho
  ret$N_rho = N_rho
  ret$X_test = X_test
  ret$N_test = N_test
  ret$res_mcleod_holdout = res_mcleod_holdout
  ret$CDF_holdout = CDF_holdout
  ret$res_mcleod_data = res_mcleod_data
  ret$CDF_data = median_curve
  ret$ind_selected_for_test = ind_selected_for_test
  class(ret) = CLASS.NAME.MCLEOD.CI

  #stop cluster if needed
  if(!CI_param$do_serial & !WORK_WITH_THREADS){
    stopCluster(cl)
  }
  
  return(ret)
  
}

#' Plot the pointwise Confidence Intervals obtained from running mcleod.estimate.CI
#' 
#' @param mcleod.CI.obj An object returned from \code{\link{mcleod.estimate.CI}}, with parameter \code{compute_CI_curves} set to \code{True}.
#' @param X_axis_as_Prob Should the X axis for the mixing distribution be presented as Probability (True, default) or as log-odds (parameter named theta, False)
#' @param add_CI_curves_on_top_of_plot Should the CI curves be plotted on top of an existing plot. This option is usefull when plotting multiple CIs for the same data.
#' @param point_estimate_color Color for the posterior median of the mixing distribution. Medians are taken point-wise across the support.
#' @param CI_curves_color Color for the curves showing the pointwise confidence intervals.
#' @param title Title for the plot
#'
#' @return NONE
#' @export
#' 
#' @examples
#' see package vignette
plot.mcleod.CI=function(mcleod.CI.obj,
                        X_axis_as_Prob = T,
                        add_CI_curves_on_top_of_plot=F,
                        point_estimate_color = 'red',
                        CI_curves_color = 'black',title = ''){
  
  not_valid_object_error_msg = 'mcleod.CI.obj must be a result returned from mcleod.estimate.CI(...), run with parameter compute_CI_curves set to true.'
  if(class(mcleod.CI.obj) != CLASS.NAME.MCLEOD.CI){
    stop(not_valid_object_error_msg)
  }
  if(!('computed_curves' %in% names(mcleod.CI.obj))){
    stop(not_valid_object_error_msg)
  }
  
  curve_obj = mcleod.CI.obj$computed_curves
  
  #the x axis is theta...
  x_axis = mcleod.CI.obj$res_mcleod_data$parameters_list$a.vec
  x_axis_label = 'theta'
  x_axis_theta = mcleod.CI.obj$bank$CI_param$theta_vec
  #unless the user asked to change it to P
  if(X_axis_as_Prob){ 
    x_axis = inv.log.odds(x_axis)
    x_axis_label = 'P'
    x_axis_theta = inv.log.odds(x_axis_theta)
  }
  #if this is not an added plot, we plot the point estimate for the data
  if(!add_CI_curves_on_top_of_plot)
    plot(x_axis,mcleod.CI.obj$CDF_data,
         col =  point_estimate_color,type = 'b',pch = 20,xlab = x_axis_label,ylab = 'CDF',main = title)
  
  #plot the CI lines, in the color the user requested
  lines(x_axis_theta,curve_obj$q_star_LE,col = CI_curves_color)
  lines(x_axis_theta,curve_obj$q_star_GE,col = CI_curves_color)
}




#' A wrapper function for mcleod.estimate.CI, used to estimate a two-sided confidence interval for the percentile of the mixing distribution at a given log-odds value.
#' 
#' The function receives input parameters as defined for \code{\link{mcleod.estimate.CI}}, together with a single log-odds value (theta). The function returns a confidence interval, in terms of CDF values, for the mixing distribution at the required point.
#' 
#' @details This function is actually a "convenience wrapper" for \code{\link{mcleod.estimate.CI}}. It is used to make sure that the only point where CIs are computed is at log-odds=theta, and that calibration of rho is also done for this point alone. 
#' 
#' @param X Same parameter as in \code{\link{mcleod.estimate.CI}}.
#' @param N Same parameter as in \code{\link{mcleod.estimate.CI}}.
#' @param theta The log-odds value for which the confidence interval will be built. For example, using a value of \code{theta=0} will return a confidence interval, in terms of CDF values, for mixing distribution at \code{theta=0}.
#' @param CI_param Same parameter as in \code{\link{mcleod.estimate.CI}}. This parameter can be used to change the confidence level.
#' @param ratio_holdout Same parameter as in \code{\link{mcleod.estimate.CI}}.
#' @param verbose Same parameter as in \code{\link{mcleod.estimate.CI}}.
#'
#' @return A vector with two entries name 'Lower' and 'Upper', denoting the two-sided CI, in terms of CDF values, for a given theta (log-odds value).
#' @export
#'
#' @examples
#'  See package vignette.
mcleod.estimate.CI.single.theta = function(X, N, theta,
                                           CI_param = mcleod.CI.estimation.parameters(),
                                           ratio_holdout = 0.1,verbose = F){
  #computing a CI for q, at a single theta
  CI_param$rho.theta_for_calibration = theta #we calibrate at a single theta. NOTE: this parameter takes precedence over CI_param$rho.q_for_calibration
  CI_param$theta_vec_for_computation = theta #and we compute Pvalues for this theta as well.
  CI_param$P_values_grid_compute_univariate_CI = T #we also notify CI param that we compute a univariate P-value. This allows for a faster stopping condition.
  
  # verify inputs and extract the verified inputs
  verified_q_and_theta_vectors = verify_q_and_theta_vec(q_vec = CI_param$q_vec,
                                                        q_vec_for_computation = CI_param$q_vec_for_computation,
                                                        theta_vec = CI_param$theta_vec,
                                                        theta_vec_for_computation = CI_param$theta_vec_for_computation,
                                                        sampling_distribution = CI_param$sampling_distribution)
  
  CI_param$n_q = verified_q_and_theta_vectors$n_q
  CI_param$n_theta = verified_q_and_theta_vectors$n_theta
  CI_param$q_vec = verified_q_and_theta_vectors$q_vec
  CI_param$q_vec_for_computation = verified_q_and_theta_vectors$q_vec_for_computation
  CI_param$theta_vec = verified_q_and_theta_vectors$theta_vec
  CI_param$theta_vec_for_computation = verified_q_and_theta_vectors$theta_vec_for_computation
  
  #estimate CI, as grid.
  CI.est.res = mcleod.estimate.CI(X = X,
                                  N = N,
                                  CI_param = CI_param,
                                  ratio_holdout = ratio_holdout,
                                  compute_P_values_over_grid = T,
                                  compute_CI_curves = F,
                                  verbose = verbose)
  
  
  alpha.one.sided = (1-CI.est.res$bank$CI_param$alpha.CI)/2
  #go over the grid and extract the lower and upper q-values for the CI (at the single theta required by the user)
  
  #Lower end:
  pvals_GE = CI.est.res$pvalues_grid$GE.pval.grid[,which(CI_param$theta_vec == theta_0)]
  ind_GE_lower_than_alpha_one_sided = which(pvals_GE <= alpha.one.sided)
  if(length(ind_GE_lower_than_alpha_one_sided)==0){
    Lower = 0  
  }else{
    Lower = CI.est.res$bank$CI_param$q_vec[max(ind_GE_lower_than_alpha_one_sided)]
  }
  
  #Higher end:
  pvals_LE = CI.est.res$pvalues_grid$LE.pval.grid[,which(CI_param$theta_vec == theta_0)]
  ind_LE_lower_than_alpha_one_sided = which(pvals_LE <= alpha.one.sided)
  if(length(ind_LE_lower_than_alpha_one_sided)==0){
    Upper = 1  
  }else{
    Upper = CI.est.res$bank$CI_param$q_vec[min(ind_LE_lower_than_alpha_one_sided)]
  }
  
  ret = c('Lower' = Lower,'Upper' = Upper)
  return(ret)
}




#' A wrapper function for mcleod.estimate.CI, used to estimate a two-sided confidence interval for the quantile of the mixing distribution at a given CDF/percentile value.
#' 
#' The function receives input parameters as defined for \code{\link{mcleod.estimate.CI}}, together with a single CDF/percentile value (name \code{q}). The function returns a confidence interval for the mixing distribution at the required percentile. For example, using a value of \code{q=0.5} will return a confidence interval, in terms of theta (log-odds), for the median of the mixing distribution.
#' 
#' @details This function is actually a "convenience wrapper" for \code{\link{mcleod.estimate.CI}}. It is used to make sure that CIs are computed for the required percentile alone. In addition, calibration of rho is done for a single theta/log-odds point: the theta for which the mixing distribution in the holdout data obtains the value closest to \code{q}. 
#'
#' @param X Same parameter as in \code{\link{mcleod.estimate.CI}}.
#' @param N Same parameter as in \code{\link{mcleod.estimate.CI}}.
#' @param q The CDF value for which the confidence interval will be built.
#' @param CI_param Same parameter as in \code{\link{mcleod.estimate.CI}}. This parameter can be used to change the confidence level.
#' @param ratio_holdout Same parameter as in \code{\link{mcleod.estimate.CI}}.
#' @param verbose Same parameter as in \code{\link{mcleod.estimate.CI}}.
#'
#' @return
#' @export
#'
#' @examples
#'  See package vignette.
mcleod.estimate.CI.single.q = function(X, N, q,
                                       CI_param = mcleod.CI.estimation.parameters(),
                                       ratio_holdout = 0.1,verbose = F){
  #computing a CI for theta, at a single q
  CI_param$rho.theta_for_calibration = NULL # no thetas are given, you have to find this d
  CI_param$rho.q_for_calibration = q #we calibrate at a single q
  CI_param$q_vec_for_computation = q #and we compute Pvalues for this q as well.
  CI_param$P_values_grid_compute_univariate_CI = T #we also notify CI param that we compute a univariate P-value. This allows for a faster stopping condition.
  
  # verify inputs and extract the verified inputs
  
  verified_q_and_theta_vectors = verify_q_and_theta_vec(q_vec = CI_param$q_vec,
                                                        q_vec_for_computation = CI_param$q_vec_for_computation,
                                                        theta_vec = CI_param$theta_vec,
                                                        theta_vec_for_computation = CI_param$theta_vec_for_computation,
                                                        sampling_distribution = CI_param$sampling_distribution)
  
  CI_param$n_q = verified_q_and_theta_vectors$n_q
  CI_param$n_theta = verified_q_and_theta_vectors$n_theta
  CI_param$q_vec = verified_q_and_theta_vectors$q_vec
  CI_param$q_vec_for_computation = verified_q_and_theta_vectors$q_vec_for_computation
  CI_param$theta_vec = verified_q_and_theta_vectors$theta_vec
  CI_param$theta_vec_for_computation = verified_q_and_theta_vectors$theta_vec_for_computation
  
  #estimate CI, as grid.
  CI.est.res = mcleod.estimate.CI(X = X,
                                  N = N,
                                  CI_param = CI_param,
                                  ratio_holdout = ratio_holdout,
                                  compute_P_values_over_grid = T,
                                  compute_CI_curves = F,
                                  verbose = verbose)
  
  
  alpha.one.sided = (1-CI.est.res$bank$CI_param$alpha.CI)/2
  
  #go over the grid and extract the lower and upper theta values for the CI (at the single q required by the user)
  
  #Right end:
  pvals_GE = CI.est.res$pvalues_grid$GE.pval.grid[which(CI_param$q_vec == q),]
  ind_GE_lower_than_alpha_one_sided = which(pvals_GE <= alpha.one.sided)
  if(length(ind_GE_lower_than_alpha_one_sided)==0){
    Upper = Inf
  }else{
    Upper = CI.est.res$bank$CI_param$theta_vec[min(ind_GE_lower_than_alpha_one_sided)]
  }
  
  #Left end:
  pvals_LE = CI.est.res$pvalues_grid$LE.pval.grid[which(CI_param$q_vec == q),]
  ind_LE_lower_than_alpha_one_sided = which(pvals_LE <= alpha.one.sided)
  if(length(ind_LE_lower_than_alpha_one_sided)==0){
    Lower = -Inf
  }else{
    Lower = CI.est.res$bank$CI_param$theta_vec[max(ind_LE_lower_than_alpha_one_sided)]
  }
  
  ret = c('Lower' = Lower,'Upper' = Upper)
  return(ret)
}